Physically-Based Visual Simulation on Graphics Hardware
Abstract
In this paper, we present a method for real-time visual simulation of diverse dynamic phenomena using programmable graphics 
hardware.  The simulations we implement use an extension of cellular automata known as the coupled map lattice (CML).  CML 
represents the state of a dynamic system as continuous values on a discrete lattice.  In our implementation we store the lattice 
values in a texture, and use pixel-level programming to implement simple next-state computations on lattice nodes and their 
neighbors.  We apply these computations successively to produce interactive visual simulations of convection, reaction-diffusion, 
and boiling.  We have built an interactive framework for building and experimenting with CML simulations running on graphics 
hardware, and have integrated them into interactive 3D graphics applications.


Introduction
Interactive 3D graphics environments, such as games, virtual 
environments, and training and flight simulators are 
becoming increasingly visually realistic, in part due to the 
power of graphics hardware.  However, these scenes often 
lack rich dynamic phenomena, such as fluids, clouds, and 
smoke, which are common to the real world.
A recent approach to the simulation of dynamic
phenomena, the coupled map lattice
[Kaneko 1993]
, uses a
set of simple local operations to model complex global 
behavior. When implemented using computer graphics 
hardware, coupled map lattices (CML) provide a simple, fast 
and flexible method for the visual simulation of a wide 
variety of dynamic systems and phenomena.
In this paper we will describe the implementation of
CML systems with current graphics hardware, and 
demonstrate the flexibility and performance of these systems 
by presenting several fast interactive 2D and 3D visual 
simulations.  Our CML boiling simulation runs at speeds 
ranging from 8 iterations per second for a 128x128x128 
lattice to over 1700 iterations per second for a 64x64 lattice.
Section 2 describes CML and other methods for
simulating natural phenomena.  Section 3  details our 
implementation of CML simulations on programmable 
graphics hardware, and Section 4 describes the specific 
simulations we have implemented.  In Section 5 we discuss 
limitations of current hardware and investigate some 
solutions.  Section 6 concludes.

CML and Related Work
The standard approach to simulating natural phenomena is to 
solve equations that describe their global behavior.  For 
example, multiple techniques have been applied to solving 
the Navier-Stokes fluid equations
[Fedkiw, et al. 2001;Foster
and Metaxas 1997;Stam 1999]
.  While their results are
typically numerically and visually accurate, many of these 
simulations require too much computation (or small lattice 
sizes) to be integrated into interactive graphics applications 
such as games.  CML models, instead of solving for the 
global behavior of a phenomenon, model the behavior by a 
number of very simple local operations.  When aggregated, 
these local operations produce a visually accurate 
approximation to the desired global behavior.
Figure 1: 3D coupled map lattice simulations running on
graphics hardware.  Left: Boiling.  Right: Reaction-Diffusion
.
109
Harris, Coombe, Scheuermann, and Lastra / Simulation on Graphics Hardware

©

The Eurographics Association 2002.

A coupled map lattice is a mapping of continuous
dynamic state values to nodes on a lattice that interact (are 
`coupled') with a set of other nodes in the lattice according 
to specified rules.  Coupled map lattices were developed by 
Kaneko for the purpose of studying spatio-temporal 
dynamics and chaos
[Kaneko 1993]
.  Since their introduction,
CML techniques have been used extensively in the fields of 
physics and mathematics for the simulation of a variety of 
phenomena, including boiling
[Yanagita 1992]
, convection
[Yanagita and Kaneko 1993]
, cloud formation
[Yanagita and
Kaneko 1997]
, chemical reaction-diffusion
[Kapral 1993]
, and
the formation of sand ripples and dunes
[Nishimori and Ouchi
1993]
.  CML techniques were recently introduced to the field
of computer graphics for the purpose of cloud modeling and 
animation
[Miyazaki, et al. 2001]
.  Lattice Boltzmann
computation is a similar technique that has been used for 
simulating fluids, particles, and other classes of phenomena
[Qian, et al. 1996]
.
A CML is an extension of a cellular automaton (CA)
[Toffoli and Margolus 1987;von Neumann 1966;Wolfram 1984]

in which the discrete state values of CA cells are replaced 
with continuous real values.  Like CA, CML are discrete in 
space and time and are a versatile technique for modeling a 
wide variety of phenomena.   Methods for animating cloud 
formation using cellular automata were presented in
[Dobashi, et al. 2000;Nagel and Raschke 1992]
.  Discrete-state
automata typically require very large lattices in order to 
simulate real phenomena, because the discrete states must be 
filtered in order to compute real values.  By using 
continuous-valued state, a CML is able to represent real 
physical quantities at each of its nodes.
While a CML model can certainly be made both
numerically and visually accurate
[Kaneko 1993]
, our
implementation on graphics hardware introduces precision 
constraints that make numerically accurate simulation 
difficult.  Therefore, our goal is instead to implement 
visually accurate simulation models on graphics hardware, in 
the hope that continuing improvement in the speed and 
precision of graphics hardware will allow numerically 
accurate simulation in the near future.
The systems that have been found to be most amenable to
CML implementation are multidimensional initial-value 
partial differential equations. These are the governing 
equations for a wide range of phenomena from fluid 
dynamics to reaction-diffusion. Based on a set of initial 
conditions, the simulation evolves forward in time.  The only 
requirement is that the equation must first be explicitly 
discretized in space and time, which is a standard 
requirement for conventional numerical simulation. This 
flexibility means that the CML can serve as a model for a 
wide class of dynamic systems.
2.1 A CML Simulation Example
To illustrate CML, we describe the boiling simulation of
[Yanagita 1992]
. The state of this simulation is the
temperature of a liquid.  A heat plate warms the lower layer 
of liquid, and temperature is diffused through the liquid. As 
the temperature reaches a threshold, the phase changes and 
"bubbles" of high temperature form. When phase changes 
occur, newly formed bubbles absorb latent heat from the 
liquid around them, and temperature differences cause them 
to float upward under buoyant force.
Yanagita implements this global behavior using four local
CML operations; Diffusion, Phase change, Buoyancy, and 
Latent heat.  Each of these operations can be written as a 
simple equation. Figures 1, 2 and 7 (see color pate) show this 
simulation running on graphics hardware, and Section 4.1 
gives details of our implementation. We will use this 
simulation as an example throughout this paper.
Hardware Implementation
Graphics hardware is an efficient processor of images ­ it 
can use texture images as input, and outputs images via 
rendering.  Images ­ arrays of values ­ map well to state 
values on a lattice.  Two-dimensional lattices can be 
represented by 2D textures, and 3D lattices by 3D textures or 
collections of 2D textures.  This natural correspondence, as 
well as the programmability and performance of graphics 
hardware, motivated our research.
3.1 Why Graphics Hardware?
Our primary reason to use graphics hardware is its speed at 
imaging operations compared to a conventional CPU.  The 
CML models we have implemented are very fast, making 
them well suited to interactive applications (See Section 4.1).
GPUs were designed as efficient coprocessors for
rendering and shading.  The programmability now available 
in GPUs such as the NVIDIA GeForce 3 and 4 and the ATI 
Radeon 8500 makes them useful coprocessors for more 
diverse applications.  Since the time between new 
generations of GPUs is currently much less than for CPUs, 
faster coprocessors are available more often than faster 
central processors.  GPU performance tracks rapid 
improvements in semiconductor technology more closely 
than CPU performance.  This is because CPUs are designed 
for high performance on sequential operations, while GPUs 
are optimized for the high parallelism of vertex and fragment 
processing
[Lindholm, et al. 2001]
.  Additional transistors can
Figure 2: A sequence of stills (10 iterations apart) from a 
2D boiling simulation running on graphics hardware.
110
Harris, Coombe, Scheuermann, and Lastra / Simulation on Graphics Hardware

©

The Eurographics Association 2002.

therefore be used to greater effect in GPU architectures.  In 
addition, programmable GPUs are inexpensive, readily 
available, easily upgradeable, and compatible with multiple 
operating systems and hardware architectures.
More importantly, interactive computer graphics
applications have many components vying for processing 
time.  Often it is difficult to efficiently perform simulation, 
rendering, and other computational tasks simultaneously 
without a drop in performance.  Since our intent is visual 
simulation, rendering is an essential part of any solution.  By 
moving simulation onto the GPU that renders the results of a 
simulation, we not only reduce computational load on the 
main CPU, but also avoid the substantial bus traffic required 
to transmit the results of a CPU simulation to the GPU for 
rendering.  In this way, methods of dynamic simulation on 
the GPU provide an additional tool for load balancing in 
complex interactive applications.
Graphics hardware also has disadvantages.  The main
problems we have encountered are the difficulty of 
programming the GPU and the lack of high precision 
fragment operations and storage.  These problems are related 
­ programming difficulty is increased by the effort required 
to ensure that precision is conserved wherever possible.
These issues should disappear with time.  Higher-level
shading languages have been introduced that make hardware 
graphics programming easier
[Peercy, et al. 2000;Proudfoot, et
al. 2001]
.  The same or similar languages will be usable for
programming simulations on graphics hardware.  We believe 
that the precision of graphics hardware will continue to 
increase, and with it the full power of programmability will 
be realised.
3.2 General-Purpose Computation
The use of computer graphics hardware for general-purpose 
computation has been an area of active research for many 
years, beginning on machines like the Ikonas
[England 1978]
,
the Pixel Machine
[Potmesil and Hoffert 1989]
and Pixel-Planes
5
[Rhoades, et al. 1992]
.  The wide deployment of
GPUs in the last several years has resulted in an increase in 
experimental research with graphics hardware.
[Trendall and
Steward 2000]
gives a detailed summary of the types of
computation available on modern GPUs.
Within the realm of graphics applications, programmable
graphics hardware has been used for procedural texturing 
and shading
[Olano and Lastra 1998; Peercy, et al. 2000;
Proudfoot, et al. 2001; Rhoades, et al. 1992]
.  Graphics
hardware has also been used for volume visualization
[Cabral, et al. 1994]
.  Recently, methods for using current and
near-future GPUs for ray tracing computations have been 
described in
[Carr, et al. 2002]
and
[Purcell, et al. 2002]
,
respectively.
Other researchers have found ways to use graphics
hardware for non-graphics applications.  The use of 
rasterization hardware for robot motion planning is described 
in
[Lengyel, et al. 1990]
.
[Hoff, et al. 1999]
describes the use
of z-buffer techniques for the computation of Voronoi
diagrams.  The PixelFlow SIMD graphics computer
[Eyles, et
al. 1997]
was used to crack UNIX password encryption
[Kedem and Ishihara 1999]
, and graphics hardware has been
used in the computation of artificial neural networks
[Bohn
1998]
.
Our work uses CML to simulate dynamic phenomena that
can be described by PDEs.  Related to this is the 
visualization of flows described by PDEs, which has been 
implemented using graphics hardware to accelerate line 
integral convolution and Lagrangian-Eulerian advection
[Heidrich, et al. 1999; Jobard, et al. 2001; Weiskopf, et al. 2001]
.
NVIDIA has demonstrated the Game of Life cellular 
automata running on their GPUs, as well as a 2D physically-based
water simulation that operates much like our CML 
simulations
[NVIDIA 2001a;NVIDIA 2001b]
.
3.3 Common Operations
A detailed description of the implementation of the specific 
simulations that we have modeled using CML would require 
more space than we have in this paper, so we will instead 
describe a few common CML operations, followed by details 
of their implementation.  Our goal in these descriptions is to 
impart a feel for the kinds of operations that can be 
performed using a graphics hardware implementation of a 
CML model.
3.3.1 Diffusion and the Laplacian
The divergence of the gradient of a scalar function is called 
the Laplacian
[Weisstein 1999]
:
2
2
2
2
2
( , )
.
T
T
T x y
x
y



=
+



The Laplacian is one of the most useful tools for working 
with partial differential equations.  It is an isotropic measure 
of the second spatial derivative of a scalar function.  
Intuitively, it can be used to detect regions of rapid change, 
and for this reason it is commonly used for edge detection in 
image processing.  The discretized form of this equation is:
2
,
1,
1,
,
1
,
1
,
4
i j
i
j
i
j
i j
i j
i j
T
T
T
T
T
T
+
+

=
+
+
+

.
The Laplacian is used in all of the CML simulations that
we have implemented.  If the results of the application of a 
Laplacian operator at a node T
i,j
are scaled and then added to
the value of T
i,j
itself, the result is diffusion
[Weisstein 1999]
:

'
2
,
,
,
4
d
i j
i j
i j
c
T
T
T
=
+

. (1)
Here,  c
d
is the coefficient of diffusion.  Application of this
diffusion operation to a lattice state will cause the state to 
diffuse through the lattice
1
.
3.3.2 Directional Forces
Most dynamic simulations involve the application of force.  
Like all operations in a CML model, forces are applied via

1
See Appendix A for details of our diffusion implementation.
111
Harris, Coombe, Scheuermann, and Lastra / Simulation on Graphics Hardware

©

The Eurographics Association 2002.

computations on the state of a node and its neighbors.  As an 
example, we describe a buoyancy operator used in 
convection and cloud formation simulations
[Miyazaki, et al.
2001;Yanagita and Kaneko 1993;Yanagita and Kaneko 1997]
.
This buoyancy operator uses temperature state T  to
compute a buoyant velocity at a node and add it to the node's 
vertical velocity state, v:

,
,
,
1,
1,
2
[2
]
b
c
i j
i j
i j
i
j
i
j
v
v
T
T
T
+
=
+


.
(2)
Equation (2) expresses that a node is buoyed upward if its 
horizontal neighbors are cooler than it is, and pushed 
downward if they are warmer. The strength of the buoyancy 
is controlled via the parameter c
b
.
3.3.3 Computation on Neighbors
Sometimes an operation requires more complex computation 
than the arithmetic of the simple buoyancy operation 
described above.  The buoyancy operation of the boiling 
simulation described in Section 2.1 must also account for 
phase change, and is therefore more complicated:


,
,
,
,
1
,
1
2
[ (
)
(
)],
( )
tanh[ (
)].
i j
i j
i j
i j
i j
c
T
T
T
T
T
T
T T





+
=

=

(3)
In Equation (3),
s is the buoyancy strength coefficient, and

(T) is an approximation of density relative to temperature,
T.  The hyperbolic tangent is used to simulate the rapid 
change of density of a substance around the phase change 
temperature,  T
c
.    A change in density of a lattice node
relative to its vertical neighbors causes the temperature of the 
node to be buoyed upward or downward.  The thing to notice 
in this equation is that simple arithmetic will not suffice ­ the 
hyperbolic tangent function must be applied to the 
temperature at the neighbors above and below node (i,j).  We 
will discuss how we can compute arbitrary functions using 
dependent texturing in Section 3.4.
3.4 State Representation and Storage
Our goal is to maintain all state and operation of our 
simulations in the GPU and its associated memory.  To this 
end, we use the frame buffer like a register array to hold 
transient state, and we use textures like main memory arrays 
for state storage.  Since the frame buffer and textures are
typically limited to storage of 8-bit unsigned integers, state 
values must be converted to this format before being written 
to texture.
Texture storage can be used for both scalar and vector
data.  Because of the four color channels used in image 
generation,  two-, three-, or four-dimensional vectors can be 
stored in each texel of an RGBA texture.  If scalar data are 
needed, it is often advantageous to store more than one scalar 
state in a single texture by using different color channels. In 
our CML implementation of the Gray-Scott reaction-diffusion
system, for example, we store the concentrations of 
both reactants in the same texture.  This is not only efficient 
in storage but also in computation since operations that act 
equivalently on both concentrations can be performed in 
parallel.
Physical simulation also requires the use of signed values.
Most texture storage, however, uses unsigned fixed-point 
values.  Although fragment-level programmability available 
in current GPUs uses signed arithmetic internally, the 
unsigned data stored in the textures must be biased and 
scaled before and after processing
[NVIDIA 2002]
.
3.5 Implementing CML Operations
An iteration of a CML simulation consists of successive 
application of simple operations on the lattice.  These 
operations consist of three steps: setup the graphics hardware 
rendering state, render a single quadrilateral fit to the view 
port, and store the rendered results into a texture. We refer to 
each of these setup-render-copy operations as a single pass.  
In practice, due to limited GPU resources (number of texture 
units, number of register combiners, etc.), a CML operation 
may span multiple passes.
The setup portion of a pass simply sets the state of the
hardware to correctly perform the rest of the pass.  To be 
sure that the correct lattice nodes are sampled during the 
pass, texels in the input textures must map directly to pixels 
in the output of the graphics pipeline.  To ensure that this is 
true, we set the view port to the resolution of the lattice, and 
the view frustum to an orthographic view fit to the lattice so 
that there is a one-to-one mapping between pixels in the 
rendering buffer and texels in the texture to be updated.
The render-copy portion of each pass performs 4
suboperations:  Neighbor Sampling,  Computation on 
Neighbors,  New State Computation, and State Update.
Figure
3 illustrates the mapping of the suboperations to
graphics hardware.  Neighbor sampling and Computation on 
Neighbors are performed by the programmable texture 
mapping hardware.  New State Computation performs 
arithmetic on the results of the previous suboperations using 
programmable texture blending.  Finally, State Update feeds 
the results of one pass to the next by rendering or copying 
the texture blending results to a texture.
Neighbor Sampling: Since state is stored in textures,
neighbor sampling  is performed by offsetting texture 
coordinates toward the neighbors of the texel being updated.  
For example, to sample the four nearest neighbor nodes of
Figure 3: Components of a CML operation map to 
graphics hardware pipeline components.
112
Harris, Coombe, Scheuermann, and Lastra / Simulation on Graphics Hardware

©

The Eurographics Association 2002.

node (x,y), the texture coordinates at the corners of the 
quadrilateral mentioned above are offset in the direction of 
each neighbor by the width of a single texel. Texture 
coordinate interpolation ensures that as rasterization 
proceeds, every texel's neighbors will be correctly sampled.  
Note that beyond sampling just the nearest neighbors of a 
node, weighted averages of nearby nodes can be computed 
by exploiting the linear texture interpolation hardware 
available in GPUs.  An example of this is our single-pass 
implementation of 2D diffusion, described in Appendix A.
Care must be taken, though, since the precision used for
the interpolation coefficients is sometimes lower than the rest 
of the texture pipeline.
Computation on Neighbors: As described in Section
3.3.3, many simulations compute complex functions of the 
neighbors they sample.  In many cases, these functions can 
be computed ahead of time and stored in a texture for use as 
a lookup table.  The programmable texture shader 
functionality of recent GPUs provides several dependent 
texture addressing operations.  We have implemented table 
lookups using the "DEPENDENT_GB_TEXTURE_ 
2D_NV" texture shader of the GeForce 3.  This shader 
provides memory indirect texture addressing ­ the green and 
blue colors read from one texture unit are used as texture 
coordinates for a lookup into a second texture unit.  By 
binding the precomputed lookup table texture to the second 
texture unit, we can implement arbitrary function operations 
on the values of the nodes (Figure 4).
New State Computation: Once we have sampled the
values of neighboring texels and optionally used them for 
function table lookups, we need to compute the new state of 
the lattice.  We use programmable hardware texture blending 
to perform arithmetic operations including addition, 
multiplication, and dot products.  On the GeForce 3 and 4, 
we implement this using register combiners
[NVIDIA 2002]

Register combiners take the output of texture shaders and 
rasterization as input, and provide arithmetic operations, 
user-defined constants, and temporary registers.  The result 
of these computations is written to the frame buffer.
State Update: Once the new state is computed, we must
store it in a state texture.  In our current implementation, we 
copy the newly-rendered frame buffer to a texture using the 
glCopyTexSubImage2D() instruction in OpenGL.  Since all 
simulation state is stored in textures, our technique avoids 
large data transfers between the CPU and GPU during 
simulation and rendering.
3.6 Numerical Range of CML Simulations
The physically based nature of CML simulations means that 
the ranges of state values for different simulations can vary 
widely.  The graphics hardware we use to implement them, 
on the other hand, operates only on fixed-point fragment 
values in the range [0,1].  This means that we must 
normalize the range of a simulation into [0,1] before it can be 
implemented in graphics hardware.
Because the hardware uses limited-precision fixed-point
numbers, some simulations will be more robust to this 
normalization than others.  The robustness of a simulation 
depends on several factors.  Dynamic range is the ratio 
between a simulation's largest absolute value and its smallest 
non-zero absolute value.  If a simulation has a high dynamic 
range, it may not be robust to normalization unless the 
precision of computation is high enough to represent the 
dynamic range.  We refer to a simulation's resolution as the 
smallest absolute numerical difference that it must be able to 
discern.  A simulation with a resolution finer than the 
resolution of the numbers used in its computation will not be 
robust.  Finally, as the arithmetic complexity of a simulation 
increases, it will incur more roundoff error, which may 
reduce its robustness when using low-precision arithmetic.
For example, the boiling simulation (Section 4.1) has a
range of approximately [0,10], but its values do not get very 
close to zero, so its dynamic range is less than ten.  Also, its 
resolution is fairly coarse, since the event to which it is most 
sensitive ­ phase change ­ is near the top of its range.  For 
these reasons, boiling is fairly robust under normalization.  
Reaction-diffusion has a range of [0,1] so it does not require 
normalization.  Its dynamic range, however, is on the order 
of 10
5
, which is much higher than that of the 8-bit

numbers
stored in textures.  Fortunately, by scaling the coefficients of 
reaction-diffusion, we can reduce this dynamic range 
somewhat to get interesting results.  However, as we 
describe in Section 4.3, it suffers from precision errors (See 
Section 5.1 for more discussion of precision issues).  As 
more precision becomes available in graphics hardware, 
normalization will become less of an issue.  When floating 
point computation is made available, simulations can be run 
within their natural ranges.
Results
We have designed and built an interactive framework, 
"CMLlab", for constructing and experimenting with CML 
simulations (Figure 5).  The user constructs a simulation 
from a set of general purpose operations, such as diffusion 
and advection, or special purpose operations designed for 
specific simulations, such as the buoyancy operations 
described in Section 3.3.  Each operation processes a set of 
input textures and produces a single output texture.  The user 
connects the outputs and inputs of the selected operations 
into a directed acyclic graph.  An iteration of the simulation 
consists of traversing the graph in depth-first fashion so that 
each operation is performed in order.  The state textures 
resulting from an iteration are used as input state for the next 
iteration, and for displaying the simulated system.  The
Figure 4: Arbitrary function lookups are implemented
using dependent texturing in graphics hardware.
113
Harris, Coombe, Scheuermann, and Lastra / Simulation on Graphics Hardware

©

The Eurographics Association 2002.

results of intermediate passes in a simulation iteration can be 
displayed to the user in place of the result textures.  This is 
useful for visually debugging the operation of a new 
simulation.
While 2D simulations in our framework use only 2D
textures for storage of lattice state, 3D simulations can be 
implemented in two ways.  The obvious way is to use 3D 
textures.  However, the poor performance of copying to 3D 
textures in current driver implementations would make our 
simulations run much slower. Instead, we implement 3D 
simulations using a collection of 2D slices to represent the 
3D volume.  This has disadvantages over using true 3D 
textures.  For example, we must implement linear filtering 
and texture boundary conditions (clamp or repeat) in 
software, wheras 3D texture functionality provides these in 
hardware.
It is worth noting that we trade optimal performance for
flexibility in the CMLLab framework.  Because we want to 
allow a variety of models to be built from a set of operations, 
we often incur the expense of some extra texture copies in 
order to keep operations separate.  Thus, our implementation 
is not optimal ­ even faster rates are achievable on the same 
hardware by sacrificing operator reuse.
To demonstrate the utility of hardware CML simulation
in interactive 3D graphics applications, we have integrated 
the simulation system into a virtual environment built on a 
3D game engine, "Wild Magic"
[Eberly 2001]
.  Figure 7 (see
color plate) is an image of a boiling witch's brew captured 
from a real-time demo we built with the engine.  The demo 
uses our 3D boiling simulation (Section 4.1) and runs at 45 
frames per second.
We will now describe three of the CML simulations that
we have implemented.  The test computer we used is a PC 
with a single 2.0 GHz Pentium 4 processor and 512 MB of 
RAM.  Tests were performed on this machine with both an 
NVIDIA GeForce 3 Ti 500 GPU with 64 MB of RAM, and 
an NVIDIA GeForce 4 Ti 4600 GPU with 128 MB of RAM.
4.1 Boiling
We have implemented 2D and 3D boiling simulations as 
described in
[Yanagita 1992]
.  Rather than simulate all
components of the boiling phenomenon (temperature, 
pressure, velocity, phase of matter, etc.), their model 
simulates only the temperature of the liquid as it boils.  The 
simulation is composed of successive application of thermal 
diffusion, bubble formation and buoyancy, latent heat 
transfer.  Sections 3.3.1 and 3.3.3 described the first two of 
these, and Section 2.1 gave an overview of the model.  For 
details of the latent heat transfer computation, we refer the 
reader to
[Yanagita 1992]
.  Our implementation requires
seven passes per iteration for the 2D simulation, and 9 passes 
per slice for the 3D simulation.  Table 1 shows the 
simulation speed for a range of resolutions.  For details of 
our boiling simulation implementation, see
[Harris 2002b]
.
4.2 Convection
The Rayleigh-Bénard convection CML model of
[Yanagita
and Kaneko 1993]
simulates convection using four CML
operations: buoyancy (described in 3.3.2), thermal diffusion, 
temperature and velocity advection, and viscosity and 
pressure effect.  The viscosity and pressure effect is 
implemented as
2
grad(div )
4
v
p
k
v
v
v k
v
= +
+
,
where
v
is the velocity, k
v
is the viscosity ratio and k
p
is the
coefficient of the pressure effect.  The first two terms of this 
equation account for diffusion of the velocity, and the last 
term is the flow caused by the gradient of the mass flow 
around the lattice
[Miyazaki, et al. 2001]
.  See
[Miyazaki, et al.
2001;Yanagita and Kaneko 1993]
for details of the discrete
implementation of this operation.
The remaining operation is advection of temperature and
velocity by the velocity field.
[Yanagita and Kaneko 1993]

implements this by distributing state from a node to its 
neighbors according to the velocity at the node. In our 
implementation, this was made difficult by the precision

Iterations Per Second
Resolution
Software  GeForce 3  GeForce 4  Speedup
64x64
266.5
1252.9
1752.5
4.7 / 6.6
128x128
61.8
679.0
926.6  11.0 / 15.0
256x256
13.9
221.3
286.6  15.9 / 20.6
512x512
3.3
61.2
82.3  18.5 / 24.9
1024x1024
.9
15.5
21.6
17.2 / 24
32x32x32
25.5
104.3
145.8
4.1 / 5.7
64x64x64
3.2
37.2
61.8  11.6 / 19.3
128x128x128
.4
NA
8.3  NA / 20.8
Table 1: A speed comparison of our hardware CML
boiling simulation to a software version.  The speedup
column gives the speedup for both GeForce 3 and 4.
Figure 5: CMLlab, our interactive framework for building
and experimenting with CML simulations.
114
Harris, Coombe, Scheuermann, and Lastra / Simulation on Graphics Hardware

©

The Eurographics Association 2002.

limitations of the hardware, so we used a texture shader-based
advection operation instead.  This operation advects 
state stored in a texture using the GL_OFFSET_TEXTURE_ 
2D_NV dependent texture addressing mode of the GeForce 3 
and 4.  A description of this method can be found in
[Weiskopf, et al. 2001]
.  Our 2D convection implementation
(Figure 8 in the color plate section) requires 10 passes per 
iteration.  We have not implemented a 3D convection 
simulation because GeForce 3 and 4 do not have a 3D 
equivalent of the offset texture operation.
Due to the precision limitations of the graphics hardware,
our implementation of convection did not behave exactly as 
described by
[Yanagita and Kaneko 1993]
.  We do observe the
formation of convective rolls, but the motion of both the 
temperature and velocity fields is quite turbulent.  We 
believe that this is a result of low-precision arithmetic.
4.3 Reaction-Diffusion
Reaction-Diffusion processes were proposed by
[Turing
1952]
and introduced to computer graphics by
[Turk
1991;Witkin and Kass 1991]
. They are a well-studied model
for the interaction of chemical reactants, and are interesting 
due to their complex and often chaotic behavior.  The 
patterns that emerge are reminiscent of patterns occurring in 
nature
[Lee, et al. 1993]
. We implemented the Gray-Scott
model, as described in
[Pearson 1993]
. This is a two-chemical
system defined by the initial value partial differential 
equations:
2
2
2
2
(1
)
(
) ,
u
v
U
D
U UV
F
U
t
V
D
V UV
F k V
t
=  +

=  +
+


where  F, k, D
u
, and D
v
.  are parameters given in
[Pearson
1993]
. We have implemented 2D and 3D versions of this
process, as shown in Figure 5 (2D), and Figures 1 and 9 (3D, 
on color plate).  We found reaction-diffusion relatively 
simple to implement in our framework because we were able 
to reuse our existing diffusion operator.  In 2D this
simulation requires two passes per iteration, and in 3D it 
requires three passes per slice.  A 256x256 lattice runs at 400 
iterations per second in our interactive framework, and a 
