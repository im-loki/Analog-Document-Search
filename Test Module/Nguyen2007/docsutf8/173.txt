Scalable Mining of Large Disk-based Graph Databases
ABSTRACT
Mining frequent structural patterns from graph databases
is an interesting problem with broad applications.
Most
of the previous studies focus on pruning unfruitful search
subspaces effectively, but few of them address the mining
on large, disk-based databases. As many graph databases
in applications cannot be held into main memory, scalable
mining of large, disk-based graph databases remains a challenging
problem. In this paper, we develop an effective index
structure, ADI (for adjacency index), to support mining various
graph patterns over large databases that cannot be held
into main memory. The index is simple and efficient to build.
Moreover, the new index structure can be easily adopted in
various existing graph pattern mining algorithms. As an example
, we adapt the well-known gSpan algorithm by using
the ADI structure. The experimental results show that the
new index structure enables the scalable graph pattern mining
over large databases. In one set of the experiments, the
new disk-based method can mine graph databases with one
million graphs, while the original gSpan algorithm can only
handle databases of up to 300 thousand graphs. Moreover,
our new method is faster than gSpan when both can run in
main memory.
Categories and Subject Descriptors
H.2.8 [Database
Applications]: Data Mining

General Terms
Algorithms, Performances.

INTRODUCTION
Mining frequent graph patterns is an interesting research
problem with broad applications, including mining struc
This research is supported in part by NSF grant IIS-0308001
and National Natural Science Foundation of China
(No. 60303008). All opinions, findings, conclusions and recommendations
in this paper are those of the authors and do
not necessarily reflect the views of the funding agencies.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD'04, August 22­25, 2004, Seattle, Washington, USA.
Copyright 2004 ACM 1-58113-888-1/04/0008 ...
$
5.00.
tural patterns from chemical compound databases, plan
databases, XML documents, web logs, citation networks,
and so forth. Several efficient algorithms have been proposed
in the previous studies [2, 5, 6, 8, 11, 9], ranging
from mining graph patterns, with and without constraints,
to mining closed graph patterns.
Most of the existing methods assume implicitly or explic-itly
that the databases are not very large, and the graphs
in the database are relatively simple. That is, either the
databases or the major part of them can fit into main memory
, and the number of possible labels in the graphs [6] is
small. For example, [11] reports the performance of gSpan,
an efficient frequent graph pattern mining algorithm, on
data sets of size up to 320 KB, using a computer with 448
MB main memory.
Clearly, the graph database and the
projected databases can be easily accommodated into main
memory.
Under the large main memory assumption, the computation
is CPU-bounded instead of I/O-bounded. Then, the
algorithms focus on effective heuristics to prune the search
space. Few of them address the concern of handling large
graph databases that cannot be held in main memory.
While the previous studies have made excellent progress
in mining graph databases of moderate size, mining large,
disk-based graph databases remains a challenging problem.
When mining a graph database that cannot fit into main
memory, the algorithms have to scan the database and navigate
the graphs repeatedly. The computation becomes I/O-bounded
.
For example, we obtain the executable of gSpan from the
authors and test its scalability. In one of our experiments
1
,
we increase the number of graphs in the database to test
the scalability of gSpan on the database size. gSpan can
only handle up to 300 thousand graphs. In another experiment
, we increase the number of possible labels in graphs.
We observe that the runtime of gSpan increases exponentially
. It finishes a data set of 300 thousand graphs with 636
seconds when there are only 10 possible labels, but needs
15 hours for a data set with the same size but the number
of possible labels is 45! This result is consistent with the
results reported in [11].
Are there any real-life applications that need to mine large
graph databases? The answer is yes. For example, in data
integration of XML documents or mining semantic web, it is
often required to find the common substructures from a huge
collection of XML documents. It is easy to see applications
with collections of millions of XML documents. There are
1
Details will be provided in Section 6
316
Research Track Paper
hundreds of even thousands of different labels. As another
example, chemical structures can be modeled as graphs. A
chemical database for drug development can contain millions
of different chemical structures, and the number of different
labels in the graphs can easily go to up to 100. These large
databases are disk-based and often cannot be held into main
memory.
Why is mining large disk-based graph databases so challenging
? In most of the previous studies, the major data
structures are designed for being held in main memory. For
example, the adjacency-list or adjacency-matrix representations
are often used to represent graphs. Moreover, most of
the previous methods are based on efficient random accesses
to elements (e.g., edges and their adjacent edges) in graphs.
However, if the adjacency-list or adjacency-matrix representations
cannot be held in main memory, the random accesses
to them become very expensive. For disk-based data, without
any index, random accesses can be extremely costly.
Can we make mining large, disk-based graph databases feasible
and scalable? This is the motivation of our study.
Since the bottleneck is the random accesses to the large
disk-based graph databases, a natural idea is to index the
graph databases properly. Designing effective and efficient
index structures is one of the most invaluable exercises in
database research. A good index structure can support a
general category of data access operations. Particularly, a
good index should be efficient and scalable in construction
and maintenance, and fast for data access.
Instead of inventing new algorithms to mine large, disk-based
graph patterns, can we devise an efficient index structure
for graph databases so that mining various graph patterns
can be conducted scalably? Moreover, the index structure
should be easy to be adopted in various existing methods
with minor adaptations.
Stimulated by the above thinking, in this paper, we study
the problem of efficient index for scalable mining of large,
disk-based graph databases, and make the following contributions
.
· By analyzing the frequent graph pattern mining problem
and the typical graph pattern mining algorithms
(taking gSpan as an example), we identify several bottleneck
data access operations in mining large, disk-based
graph databases.
· We propose ADI (for adjacency index), an effective
index structure for graphs. We show that the major
operations in graph mining can be facilitated efficiently
by an ADI structure. The construction algorithm of
ADI structure is presented.
· We adapt the gSpan algorithm by using the ADI structure
on mining large, disk-based graph databases, and
achieve algorithm ADI-Mine. We show that ADI-Mine
outperforms gSpan in mining complex graph databases
and can mine much larger databases than gSpan.
· A systematic performance study is reported to verify
our design. The results show that our new index structure
and algorithm are scalable on large data sets.
The remainder of the paper is organized as follows. We
define the problem of frequent graph pattern mining in Section
2. The idea of minimum DFS code and algorithm gSpan
b
b
a
a
y
z
x
x
x
x
z
a
a
b
v3
v2
v1
v0
b
b
a
a
y
z
x
x
v3
v2
v0
v1
b
b
a
a
y
z
x
x
(a) Graph
(b) Subgraph
(c) DFS-tree
(d) DFS-tree
G
G
T
1
T
2
Figure 1: Subgraph and DFS codes
are reviewed in Section 3, and the major data access operations
in graph mining are also identified. The ADI structure
is developed in Section 4. The efficient algorithm ADI-Mine
for mining large, disk-based graph databases using ADI is
presented in Section 5.
The experimental results are reported
in Section 6. The related work is discussed in Section
7. Section 8 concludes the paper.
PROBLEM DEFINITION
In this paper, we focus on undirected labeled simple graphs.
A labeled graph is a 4-tuple G = (V, E, L, l), where V is a set
of vertices, E
V × V is a set of edges, L is a set of labels,
and l : V
E  L is a labeling function that assigns a label
to an edge or a vertex. We denote the vertex set and the
edge set of a graph G by V (G) and E(G), respectively.
A graph G is called connected if for any vertices u, v

V (G), there exist vertices w
1
, . . . , w
n
V (G) such that
{(u, w
1
), (w
1
, w
2
), . . . , (w
n-1
, w
n
), (w
n
, v)
}  E(G).
Frequent patterns in graphs are defined based on subgraph
isomorphism.
Definition 1
(Subgraph isomorphism). Given graphs
G = (V, E, L, l) and G = (V , E , L , l ). An injective function
f : V
V is called a subgraph isomorphism from G to
G if (1) for any vertex u
V , f(u)  V and l (u) = l(f(u));
and (2) for any edge (u, v)
E , (f(u), f(v))  E and
l
(u, v) = l(f (u), f (v)).
If there exists a subgraph isomorphism from G to G, then
G
is called a subgraph of G and G is called a supergraph of
G
, denoted as G
G.
For example, the graph G in Figure 1(b) is a subgraph of
G in Figure 1(a).
A graph database is a set of tuples (gid, G), where gid is
a graph identity and G is a graph. Given a graph database
GDB, the support of a graph G in GDB, denoted as sup(G )
for short, is the number of graphs in the database that are
supergraphs of G , i.e.,
|{(gid, G)  GDB|G
G
}|.
For a support threshold min sup (0
min sup  |GDB|),
a graph G is called a frequent graph pattern if sup(G )

min sup
. In many applications, users are only interested
in the frequent recurring components of graphs. Thus, we
put a constraint on the graph patterns: we only find the
frequent graph patterns that are connected.
Problem definition. Given a graph database GDB and
a support threshold min sup. The problem of mining frequent
connected graph patterns is to find the complete set of
connected graphs that are frequent in GDB.
317
Research Track Paper
MINIMUM DFS CODE AND GSPAN
In [11], Yan and Han developed the lexicographic ordering
technique to facilitate the graph pattern mining. They
also propose an efficient algorithm, gSpan, one of the most
efficient graph pattern mining algorithms so far.
In this
section, we review the essential ideas of gSpan, and point
out the bottlenecks in the graph pattern mining from large
disk-based databases.
3.1
Minimum DFS Code
In order to enumerate all frequent graph patterns efficiently
, we want to identify a linear order on a representation
of all graph patterns such that if two graphs are in identical
representation, then they are isomorphic. Moreover, all the
(possible) graph patterns can be enumerated in the order
without any redundancy.
The depth-first search tree (DFS-tree for short) [3] is popularly
used for navigating connected graphs.
Thus, it is
natural to encode the edges and vertices in a graph based
on its DFS-tree. All the vertices in G can be encoded in
the pre-order of T . However, the DFS-tree is generally not
unique for a graph. That is, there can be multiple DFS-trees
corresponding to a given graph.
For example, Figures 1(c) and 1(d) show two DFS-trees of
the graph G in Figure 1(a). The thick edges in Figures 1(c)
and 1(d) are those in the DFS-trees, and are called forward
edges, while the thin edges are those not in the DFS-trees,
and are called backward edges. The vertices in the graph
are encoded v
0
to v
3
according to the pre-order of the corresponding
DFS-trees.
To solve the uniqueness problem, a minimum DFS code
notation is proposed in [11].
For any connected graph G, let T be a DFS-tree of G.
Then, an edge is always listed as (v
i
, v
j
) such that i &lt; j. A
linear order
on the edges in G can be defined as follows.
Given edges e = (v
i
, v
j
) and e = (v
i
, v
j
). e
e if (1)
when both e and e are forward edges (i.e., in DFS-tree T ),
j &lt; j
or (i &gt; i
j = j ); (2) when both e and e are
backward edges (i.e., edges not in DFS-tree T ), i &lt; i or
(i = i
j &lt; j ); (3) when e is a forward edge and e is a
backward edge, j
i ; or (4) when e is a backward edge and
e
is a forward edge, i &lt; j .
For a graph G and a DFS-tree T , a list of all edges in
E(G) in order
is called the DFS code of G with respect to
T , denoted as code(G, T ). For example, the DFS code with
respect to the DFS-tree T
1
in Figure 1(c) is code(G, T
1
) =
(v
0
, v
1
, x, a, x)-(v
1
, v
2
, x, a, z)-(v
2
, v
0
, z, b, x)-(v
1
, v
3
, x, b, y) ,
where an edge (v
i
, v
j
) is written as (v
i
, v
j
, l(v
i
), l(v
i
, v
j
),
l(v
j
)), i.e., the labels are included. Similarly, the DFS code
with respect to the DFS-tree T
2
in Figure 1(d) is
code(G, T
2
) = (v
0
, v
1
, y, b, x)-(v
1
, v
2
, x, a, x)-(v
2
, v
3
, x, b, z)
(v
3
, v
1
, z, a, x) .
Suppose there is a linear order over the label set L. Then,
for DFS-trees T
1
and T
2
on the same graph G, their DFS
codes can be compared lexically according to the labels of
the edges. For example, we have code(G, T
1
) &lt; code(G, T
2
)
in Figures 1(c) and 1(d).
The lexically minimum DFS code is selected as the representation
of the graph, denoted as min(G). In our example
in Figure 1, min(G) = code(G, T
1
).
Minimum DFS code has a nice property: two graphs G
and G are isomorphic if and only if min(G) = min(G ).
Moreover, with the minimum DFS code of graphs, the prob-Input
: a DFS code s, a graph database GDB and min sup
Output: the frequent graph patterns
Method:
if s is not a minimum DFS code then return;
output s as a pattern if s is frequent in GDB;
let C =
;
scan GDB once, find every edge e such that
e can be concatenated to s to form a DFS code s
e
and s
e is frequent; C = C
{s e};
sort the DFS codes in C in lexicographic order;
for each s e  C in lexicographic order do
call gSpan(s e, GDB, min sup);
return;
Figure 2: Algorithm
gSpan.
lem of mining frequent graph patterns is reduced to mining
frequent minimum DFS codes, which are sequences, with
some constraints that preserve the connectivity of the graph
patterns.
3.2
Algorithm gSpan
Based on the minimum DFS codes of graphs, a depth-first
search, pattern-growth algorithm, gSpan, is developed
in [11], as shown in Figure 2. The central idea is to conduct
a depth-first search of minimum DFS codes of possible
graph patterns, and obtain longer DFS codes of larger
graph patterns by attaching new edges to the end of the
minimum DFS code of the existing graph pattern.
The
anti-monotonicity of frequent graph patterns, i.e., any super
pattern of an infrequent graph pattern cannot be frequent, is
used to prune.
Comparing to the previous methods on graph pattern
mining, gSpan is efficient, since gSpan employs the smart
idea of minimum DFS codes of graph patterns that facilitates
the isomorphism test and pattern enumeration. Moreover
, gSpan inherits the depth-first search, pattern-growth
methodology to avoid any candidate-generation-and-test. As
reported in [11], the advantages of gSpan are verified by the
experimental results on both real data sets and synthetic
data sets.
3.3
Bottlenecks in Mining Disk-based Graph
Databases
Algorithm gSpan is efficient when the database can be
held into main memory. For example, in [11], gSpan is scalable
for databases of size up to 320 KB using a computer
with 448 MB main memory. However, it may encounter difficulties
when mining large databases. The major overhead
is that gSpan has to randomly access elements (e.g., edges
and vertices) in the graph database as well as the projections
of the graph database many times. For databases that
cannot be held into main memory, the mining becomes I/O
bounded and thus is costly.
Random accesses to elements in graph databases and checking
the isomorphism are not unique to gSpan. Instead, such
operations are extensive in many graph pattern mining algorithms
, such as FSG [6] (another efficient frequent graph
pattern mining algorithm) and CloseGraph [9] (an efficient
algorithm for mining frequent closed graph patterns).
In mining frequent graph patterns, the major data access
operations are as follows.
318
Research Track Paper
OP1: Edge support checking. Find the support of an
edge (l
u
, l
e
, l
v
), where l
u
and l
v
are the labels of vertices
and l
e
is the label of the edge, respectively;
OP2: Edge-host graph checking. For an edge e
=
(l
u
, l
e
, l
v
), find the graphs in the database where e appears
;
OP3: Adjacent edge checking. For
an
edge
e
=
(l
u
, l
e
, l
v
), find the adjacent edges of e in the graphs
where e appears, so that the adjacent edges can be
used to expand the current graph pattern to larger
ones.
Each of the above operations may happen many times
during the mining of frequent graph patterns. Without an
appropriate index, each of the above operations may have to
scan the graph database or its projections. If the database
and its projections cannot fit into main memory, the scanning
and checking can be very costly.
Can we devise an index structure so that the related information
can be kept and all the above operations can be
achieved using the index only, and thus without scanning
the graph database and checking the graphs? This motivates
the design of the ADI structure.
THE ADI STRUCTURE
In this section we will devise an effective data structure,
ADI (for adjacency index), to facilitate the scalable mining
of frequent graph patterns from disk-based graph databases.
4.1
Data Structure
The ADI index structure is a three-level index for edges,
graph-ids and adjacency information. An example is shown
in Figure 3, where two graphs, G
1
and G
2
, are indexed.
4.1.1
Edge Table
There can be many edges in a graph database. The edges
are often retrieved by the labels during the graph pattern
mining, such as in the operations identified in Section 3.3.
Therefore, the edges are indexed by their labels in the ADI
structure.
In ADI, an edge e = (u, v) is recorded as a tuple
(l(u), l(u, v), l(v)) in the edge table, and is indexed by the
labels of the vertices, i.e., l(u) and l(v), and the label of
the edge itself, i.e., l(u, v). Each edge appears only once in
the edge table, no matter how many times it appears in the
graphs. For example, in Figure 3, edge (A, d, C) appears
once in graph G
1
and twice in graph G
2
. However, there
is only one entry for the edge in the edge table in the ADI
structure.
All edges in the edge table in the ADI structure are sorted.
When the edge table is stored on disk, a B+-tree is built on
the edges. When part of the edge table is loaded into main
memory, it is organized as a sorted list. Thus, binary search
can be conducted.
4.1.2
Linked Lists of Graph-ids
For each edge e, the identities of the graphs that contain
e form a linked list of graph-ids. Graph-id G
i
is in the list
of edge e if and only if there exists at least one instance of e
in G
i
. For example, in Figure 3, both G
1
and G
2
appear in
the list of edge (A, d, C), since the edge appears in G
1
once
and in G
2
twice. Please note that the identity of graph G
i
G1
G2
G1
G2
G2
G1
A
B
C
D
a
d
d
b
1
2
3
4
G1
A
B
C
C
D
B
a
c
d
d
d
1
2
3
4
5
G2
Edges
Block 1
Block 2
Graph-ids (on disk)
1  2
2  3
1  4
3  4
1  2
1  4
1  6
2  3
4  5
(A, a, B)
(A, d, C)
(B, b, D)
G2
G1
(B, c, C)
(B, d, D)
(C, d, D)
Adjacency (on disk)
6
Figure 3: An
ADI structure.
appears in the linked list of edge e only once if e appears in
G
i
, no matter how many times edge e appears in G
i
.
A list of graph-ids of an edge are stored together. Therefore
, given an edge, it is efficient to retrieve all the identities
of graphs that contain the edge.
Every entry in the edge table is linked to its graph-id
linked list. By this linkage, the operation OP2: edge-host
graph checking can be conducted efficiently. Moreover, to
facilitate operation OP1: edge support checking, the length
of the graph-id linked list, i.e., the support of an edge, is
registered in the edge table.
4.1.3
Adjacency Information
The edges in a graph are stored as a list of the edges
encoded. Adjacent edges are linked together by the common
vertices, as shown in Figure 3. For example, in block 1,
all the vertices having the same label (e.g., 1) are linked
together as a list. Since each edge has two vertices, only
two pointers are needed for each edge.
Moreover, all the edges in a graph are physically stored
in one block on disk (or on consecutive blocks if more space
is needed), so that the information about a graph can be
retrieved by reading one or several consecutive blocks from
disk. Often, when the graph is not large, a disk-page (e.g.,
of size 4k) can hold more than one graph.
Encoded edges recording the adjacency information are
linked to the graph-ids that are further associated with the
edges in the edge table.
4.2
Space Requirement
The storage of an ADI structure is flexible. If the graph
database is small, then the whole index can be held into
main memory. On the other hand, if the graph database
is large and thus the ADI structure cannot fit into main
319
Research Track Paper
memory, some levels can be stored on disk. The level of
adjacency information is the most detailed and can be put
on disk. If the main memory is too small to hold the graph-id
linked lists, they can also be accommodated on disk. In
the extreme case, even the edge table can be held on disk
and a B+-tree or hash index can be built on the edge table.
Theorem 1
(Space complexity). For graph database
GDB
=
{G
1
, . . . , G
n
},
the
space
complexity
is
O(
n
i=1
|E(G
i
)
|).
Proof. The space complexity is determined by the following
facts. (1) The number of tuples in the edge table is equal to
the number of distinct edges in the graph database, which is
bounded by
n
i=1
|E(G
i
)
|; (2) The number of entries in the
graph-id linked lists in the worst case is the number of edges
in the graph database, i.e.,
n
i=1
|E(G
i
)
| again; and (3) The
adjacency information part records every edge exactly once.
Please note that, in many application, it is reasonable to
assume that the edge table can be held into main memory.
For example, suppose we have 1, 000 distinct vertex labels
and 1, 000 distinct edge labels. There can be up to 1000
×
999
÷ 2 × 1000 = 4.995 × 10
8
different edges, i.e., all possible
combinations of vertex and edge labels. Suppose up to 1%
edges are frequent, there are only less than 5 million different
edges, and thus the edge table can be easily held into main
memory.
In real applications, the graphs are often sparse, that is,
not all possible combinations of vertex and edge labels appear
in the graphs as an edge. Moreover, users are often
interested in only those frequent edges. That shrinks the
edge table substantially.
4.3
Search Using ADI
Now, let us examine how the ADI structure can facilitate
the major data access operations in graph pattern mining
that are identified in Section 3.3.
OP1: Edge support checking Once an ADI structure is
constructed, this information is registered on the edge
table for every edge. We only need to search the edge
table, which is either indexed (when the table is on
disk) or can be searched using binary search (when
the table is in main memory).
In some cases, we may need to count the support of an
edge in a subset of graphs G
G. Then, the linked
list of the graph-ids of the edge is searched. There is
no need to touch any record in the adjacency information
part. That is, we do not need to search any detail
about the edges. Moreover, for counting supports of
edges in projected databases, we can maintain the support
of each edge in the current projected database and
thus we do not even search the graph-id linked lists.
OP2: Edge-host graph checking We only need to search
the edge table for the specific edge and follow the link
from the edge to the list of graph-ids. There is no
need to search any detail from the part of adjacency
information.
OP3: Adjacent edge checking Again, we start from an
entry in the edge table and follow the links to find
the list of graphs where the edge appears. Then, only
Input: a graph database GDB and min sup
Output: the ADI structure
Method:
scan GDB once, find the frequent edges;
initialize the edge table for frequent edges;
for each graph do
remove infrequent edges;
compute the mininmum DFS code [11];
use the DFS-tree to encode the vertices;
store the edges in the graph onto disk and form
the adjacency information;
for each edge do
insert the graph-id to the graph-id list
associated with the edge;
link the graph-id to the related adjacency
information;
end for
end for
Figure 4: Algorithm of
ADI construction.
the blocks containing the details of the instances of the
edge are visited, and there is no need to scan the whole
database. The average I/O complexity is O(log n +
m + l), where n is the number of distinct edges in the
graph, m is the average number of graph-ids in the
linked lists of edges, and l is the average number of
blocks occupied by a graph. In many applications, m
is orders of magnitudes smaller than the n, and l is a
very small number (e.g., 1 or 2).
The algorithms for the above operations are simple. Limited
by space, we omit the details here. As can be seen,
once the ADI structure is constructed, there is no need to
scan the database for any of the above operations. That is,
the ADI structure can support the random accesses and the
mining efficiently.
4.4
Construction of ADI
Given a graph database, the corresponding ADI structure
is easy to construct by scanning the database only twice.
In the first scan, the frequent edges are identified. According
to the apriori property of frequent graph patterns, only
those frequent edges can appear in frequent graph patterns
and thus should be indexed in the ADI structure. After the
first scan, the edge table of frequent edges is initialized.
In the second scan, graphs in the database are read and
processed one by one. For each graph, the vertices are encoded
according to the DFS-tree in the minimum DFS code,
as described in [11] and Section 3. Only the vertices involved
in some frequent edges should be encoded. Then, for each
frequent edge, the graph-id is inserted into the corresponding
linked list, and the adjacency information is stored. The
sketch of the algorithm is shown in Figure 4.
Cost Analysis
There are two major costs in the ADI construction: writing
the adjacency information and updating the linked lists of
graph-ids. Since all edges in a graph will reside on a disk
page or several consecutive disk pages, the writing of adjacency
information is sequential. Thus, the cost of writing
adjacency information is comparable to that of making a
320
Research Track Paper
4
3
2
1
D
C
A
B
a
d  1
d  3
d  4
b  2
a  1
b  3
d  4
a  2
4  C
3  D
2  B
1  A
d
d
b
(a) The graph and the adjacency-lists
1 A
2 B
3 D
4 C
1 A
0
a
0
d
2 B
a
0
b
0
3 D
0
b
0
d
4 C
d
0
d
0
(b) The adjacency-matrix
Figure 5: The adjacency-list and adjacency-matrix
representations of graphs.
copy of the original database plus some bookkeeping.
Updating the linked lists of graph-ids requires random
accesses to the edge table and the linked lists. In many
cases, the edge table can be held into main memory, but not
the linked list. Therefore, it is important to cache the linked
lists of graph-ids in a buffer. The linked lists can be cached
according to the frequency of the corresponding edges.
Constructing ADI for large, disk-based graph database
may not be cheap. However, the ADI structure can be built
once and used by the mining many times. That is, we can
build an ADI structure using a very low support threshold,
or even set min sup = 1.
2
The index is stored on disk.
Then, the mining in the future can use the index directly,
as long as the support threshold is no less than the one that
is used in the ADI structure construction.
4.5
Projected Databases Using ADI
Many depth-first search, pattern-growth algorithms utilize
proper projected databases. During the depth-first search
in graph pattern mining, the graphs containing the current
graph pattern P should be collected and form the P projected
database. Then, the further search of larger graph
patterns having P as the prefix of their minimum DFS codes
can be achieved by searching only the P -projected database.
Interestingly, the projected databases can be constructed
using ADI structures. A projected database can be stored
in the form of an ADI structure. In fact, only the edge table
and the list of graph-ids should be constructed for a new
projected database and the adjacency information residing
on disk can be shared by all projected databases.
That
can save a lot of time and space when mining large graph
databases that contain many graph patterns, where many
projected databases may have to be constructed.
4.6
Why Is ADI Good for Large Databases?
In most of the previous methods for graph pattern mining,
the adjacency-list or adjacency-matrix representations are
used to represent graphs. Each graph is represented by an
adjacency-matrix or a set of adjacency-lists. An example is
shown in Figure 5.
2
If min sup = 1, then the ADI structure can be constructed
by scanning the graph database only once. We do not need
to find frequent edges, since every edge appearing in the
graph database is frequent.
In Figure 5(a), the adjacency-lists have 8 nodes and 8
pointers. It stores the same information as Block 1 in Figure
3, where the block has 4 nodes and 12 pointers.
The space requirements of adjacency-lists and ADI structure
are comparable. From the figure, we can see that each
edge in a graph has to be stored twice: one instance for
each vertex. (If we want to remove this redundancy, the
tradeoff is the substantial increase of cost in finding adjacency
information). In general, for a graph of n edges, the
adjacency-list representation needs 2n nodes and 2n pointers
. An ADI structure stores each edge once, and use the
linkage among the edges from the same vertex to record the
adjacency information. In general, for a graph of n edges, it
needs n nodes and 3n pointers.
Then, what is the advantage of ADI structure against
adjacency-list representation? The key advantage is that the
ADI structure extracts the information about containments
of edges in graphs in the first two levels (i.e., the edge table
and the linked list of graph-ids). Therefore, in many operations
, such as the edge support checking and edge-host graph
checking, there is no need to visit the adjacency information
at all. To the contrast, if the adjacency-list representation
is used, every operation has to check the linked lists. When
the database is large so that either the adjacency-lists of all
graphs or the adjacency information in the ADI structure
cannot be accommodated into main memory, using the first
two levels of the ADI structure can save many calls to the
adjacency information, while the adjacency-lists of various
graphs have to be transferred between the main memory and
the disk many times.
Usually, the adjacency-matrix is sparse. The adjacency-matrix
representation is inefficient in space and thus is not
used.
ALGORITHM ADI-MINE
With the help from the ADI structure, how can we improve
the scalability and efficiency of frequent graph pattern
mining? Here, we present a pattern-growth algorithm ADI-Mine
, which is an improvement of algorithm gSpan. The
algorithm is shown in Figure 6.
If the ADI structure is unavailable, then the algorithm
scans the graph database and constructs the index. Otherwise
, it just uses the ADI structure on the disk.
The frequent edges can be obtained from the edge table in
the ADI structure. Each frequent edge is one of the smallest
frequent graph patterns and thus should be output. Then,
the frequent edges should be used as the "seeds" to grow
larger frequent graph patterns, and the frequent adjacent
edges of e should be used in the pattern-growth. An edge
e
is a frequent adjacent edge of e if e is an adjacent edge of
e in at least min sup graphs. The set of frequent adjacent
edges can be retrieved efficiently from the ADI structure
since the identities of the graphs containing e are indexed
as a linked-list, and the adjacent edges are also indexed in
the adjacency infor