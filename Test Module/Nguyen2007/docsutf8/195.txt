Topic Transition Detection Using Hierarchical Hidden Markov and Semi-Markov Models
ABSTRACT
In this paper we introduce a probabilistic framework to exploit
hierarchy, structure sharing and duration information
for topic transition detection in videos. Our probabilistic detection
framework is a combination of a shot classification
step and a detection phase using hierarchical probabilistic
models. We consider two models in this paper: the extended
Hierarchical Hidden Markov Model (HHMM) and the Coxian
Switching Hidden semi-Markov Model (S-HSMM) because
they allow the natural decomposition of semantics in
videos, including shared structures, to be modeled directly,
and thus enabling efficient inference and reducing the sample
complexity in learning. Additionally, the S-HSMM allows
the duration information to be incorporated, consequently
the modeling of long-term dependencies in videos
is enriched through both hierarchical and duration modeling
. Furthermore, the use of the Coxian distribution in the
S-HSMM makes it tractable to deal with long sequences in
video. Our experimentation of the proposed framework on
twelve educational and training videos shows that both models
outperform the baseline cases (flat HMM and HSMM)
and performances reported in earlier work in topic detection
. The superior performance of the S-HSMM over the
HHMM verifies our belief that duration information is an
important factor in video content modeling.
Categories and Subject Descriptors
H.3.1 [Information
Storage and Retrieval]: Content Analysis and Indexing.
General Terms
Algorithms, Management

INTRODUCTION
The ultimate goal of the video segmentation problem is to
characterize the temporal dynamics of the video whereby it
can be segmented into coherent units, possibly at different
levels of abstraction. Seeking abstract units to move beyond
the shots has thus been an active topic of much recent re-Permission
to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
MM'05, November 6­11, 2005, Singapore.
Copyright 2005 ACM 1-59593-044-2/05/0011 ...
$
5.00.
search. While the problem of shot transition is largely solved
at a satisfactory level [7], the `abstract units' or scene detection
problem is much harder, partially due to the following
three challenges identified in [29]: (a) the variety in directional
styles, (b) the semantic relationship of neighbouring
scenes, and (c) the knowledge of the viewer about the world.
While the last aspect is beyond the scope of this work, the
first two clearly imply that effective modeling of high-level
semantics requires the domain knowledge (directional style)
and the modeling of long-term, multiple-scale correlations
of the video dynamics (neighboring semantic relationship).
Modeling temporal correlations over a long period is generally
a challenging problem. As we shall review in the
subsequent section, this problem is usually solved in a specific
domain setting so that the expert knowledge about the
domain can be utilised. While organization of content in
generic videos (e.g., movies) is too diverse to be fully char-acterized
by statistical models, the hierarchy of semantic
structure in the class of education-oriented videos is more
defined, exposing strong temporal correlation in time, and
thus make it more desirable to probabilistic modeling. In
this paper, we concentrate on this video genre and develop
an effective framework to segment these videos into topi-cally
correlated units. This problem is an important step
to enable abstraction, summarization, and browsing of educational
content ­ a rich class of film genre that has an
increasing important role in building e-services for learning
and training.
Probabilistic modeling of temporal correlations in video
data is however a difficult problem. It is complicated because
the underlying semantics naturally possess a hierarchical
decomposition with possible existence of tight structure
sharing between high-level semantics. In addition, the
typical duration for these structures usually varies for each
of its higher semantic. As an example, assisted narration ­ a
section that involves the narrator talking to the audience ­ is
usually used in both the introduction and in the main body
of a topic in an educational video. However while one, or
rarely two, shots of assisted narration (AN) are considered
sufficient for the introduction, the body typically requires
many AN shots. Thus it is important to exploit and fuse
hierarchical decomposition, structure sharing and duration
information in a unified framework to effectively address the
problem of topic transition detection.
The most widely used pobabilistic model is the hidden
Markov model (HMM). However, in many cases, the HMM
is unsuitable for video analysis since the strong Markov assumption
makes it too restrictive to capture correlations
11
over long periods. This limitation is usually overcome in the
literature by the use of a series of HMMs in a hierarchic manner
. The underlying problem in these approaches still is the
manual combination of HMMs at the higher levels which results
in the excessive expense of preparing the training data
and, more importantly, the interaction across higher semantic
levels is not incorporated during model training. One
rigorous approach to overcome this limitation is the use of
the Hierarchical Hidden Markov Model (HHMM), first introduced
in [6] and later extended to handle structure sharing
in [3]. The sophisticated model in [3] allows natural hierarchical
organization of the videos, including any existing
structure sharing, to be modeled rigorously. Practically this
will result in computational savings and a reduction in sample
complexity for learning. Given its advantages, we use
this model in this paper to model educational video content
for topic transition detection.
It is natural to see that durative properties play an important
role in human perception. An excessively long lecture
would bore the students. As such, education-oriented videos
(e.g., news, documentaries, lectures, training videos, etc.)
exhibit strong duration information in their content. We
thus propose an alternative approach towards handling temporal
dependencies over long periods through the explicit
modeling of duration information captured in semi-Markov
models. In these models, a state is assumed to remain un-changed
for some duration of time before it transits to a
new state, and thus it addresses the violation of the strong
Markov assumption from having states whose duration distributions
are non-geometric.
Existing semi-Markov models commonly model duration
distributions as multinomials. Video data is however typically
very long, thus making a multinomial semi-Markov
model unsuitable for video analysis since it would result in
both excessive computation and the number of parameters
required. Continuous modeling of duration does exist such
as in the use of the Gamma distribution, or more generally
the exponential family, described in [12, 16] to provide
more compact parameterization. However, there are still
two limitations applied to these models for video analysis:
(a) learning these distributions requires numerical optimiza-tion
and the time complexity still depends on the maximum
duration length, and (b) no hierarchical modeling has been
attempted. Fortunately, in [5], a Switching Hidden Semi-Markov
Model (S-HSMM) is introduced in which the duration
is modeled as a discrete M -phase Coxian distribution
. This model is particularly interesting for video analysis
since: (1) it can model hierarchical decomposition, and
(2) the Coxian duration modeling results in fast learning
and inference, the number of parameters is small and close-formed
estimation exists. Parameterizing long-term temporal
correlations existing in video is thus enriched by both
the hierarchical architecture and the duration modeling at
the bottom level of the S-HSMM.
To model video content, we argue that it is beneficial to
exploit both the hierarchical organization of the videos, their
semantically shared substructures and typical durations of
important semantics. These aspects are all addressed in
this paper in a unified and coherent probabilistic framework
. We use the HHMM and the S-HSMM and propose
a two-phase architecture for detecting topical transition in
educational videos. In the first phase, shots are classified
into meaningful labels. Using classified shot labels, the second
phase trains a hierarchical probabilistic model (HHMM
or S-HSMM) which is then used at a later stage for segmentation
and annotation. Prior knowledge about the domain,
including shared structures, is incorporated into the topo-logical
structure during training.
Our cross-validation on a dataset including a mix of twelve
videos demonstrates promising results. The performances
from the baseline cases (HMM and HSMM) have shown
that they are too restrictive and unsuitable in our detection
scheme, proving the validity of hierarchical modeling.
The performances of the hierarchical models, including the
HHMM and S-HSMM, are shown to surpass all results reported
in earlier work in topic detection [23, 20, 4]. The
superior performance of the S-HSMM over the HHMM has
also demonstrated our belief that duration information is
indeed an important element in the segmentation problem.
Exploiting the hierarchy, structure sharing and duration
in a unified probabilistic framework, our contributions are
twofold: (1) we provide a coherent hierarchical probabilistic
framework for topic detection. Although the current report
concentrates on the educational genre, this framework can
clearly generalize to other genres such as news and documentaries
, and (2) to our knowledge we are the first to investigate
duration and hierarchical modeling for video segmentation
1
in a unified framework.
The remainder of this paper is organized as follows. In
the next section, we provide related background to this work.
This is followed by a detailed section on the detection framework
including the description of the HHMM and S-HSMM.
We detail the shot classification phase in Section 4. Experimental
results are then reported in Section 5. Finally, the
conclusion follows in Section 6.
RELATED BACKGROUND
Seeking high-level semantics to move beyond the shots has
been the central theme of much recent research. Attempts
towards this problem have resulted in a fast growing body
of work, and depending on the investigating domain, the abstracting
units appear under different names such as scene,
story, episode for motion pictures; topic, subtopic, macro
segments, story units for information-oriented videos (news,
documentaries, training and educational videos), or general
term like logical story units used in [8, 32]. Otherwise stated,
we shall the term `scene' in this section to mean all of the
aforementioned names.
Early attempts have targeted extracting scene-level concepts
in broadcast programs, in particular news videos (e.g., [9,
14, 26]). In these attempts, the semantic extraction problem
is usually cast as the classification problem. The authors
in [26], for example, combine a number of visual and
aural low-level features together with shot syntax presented
in news videos to group shots into different narrative structures
and label them as anchor-shot, voice-over, or inter-1
Since topic change coincides with a shot transition, the shot
boundary provides crucial information in detecting topic
transitions, therefore the term `duration' in this work is calculated
in terms of the number of shots. This drastically
simplifies the modeling process. An alternative way of modeling
duration is to uniformly replicate a shot label based on
its length. However, doing this would require an extra modeling
of shot transition knowledge. In this work, we avoid
this complication and concentrate on duration information
based on the shot counts.
12
view. Liu et al. [14] propose a video/audio fusion approach
to segment news reports from other categories in broadcast
programs with different types of classifiers (simple threshold
method, Gaussian mixture classifier, and support vector machine
). Ide et al. [9] propose an automatic indexing scheme
for news video where shots are indexed based on the image
content and keywords into five categories: speech/report,
anchor, walking, gathering, and computer graphics. Caption
text information is then used with classified shots to
build the indices.
Segmentation of the news story is the second major theme
explored in the broadcast domain. The common underlying
approach used in these works is the use of explicit `rules'
about the structure of news programs to locate the transitions
of a news story. Commonly accepted heuristics are for
example: a news story often starts and finishes with anchor-person
shots [31]; the start of a news story is usually coupled
with music [2]; or a relative long silence period is the indication
of the boundary between two news stories [33]. More
complicated rules via temporal analysis are also exploited
such as the work of [37] which utilises detection results of
anchor-persons and captions to form a richer set of rules
(i.e., if the same text caption appears in two consecutive
anchor-person shots, then they belong to the same news
story). There is also a body of work which casts the segmentation
problem of news story in a HMM framework [10,
4]. The authors in [10], for example, propose the news segmentation
problem as problem of decoding the maximum
state sequence of a trained HMM whose transition matrix is
tailored by explicit rules about the news program. A somewhat
similar approach to the work in this paper is [4] (whose
results came first in the TRECVID2003 story segmentation
benchmark). Shots in [4] are first classified into a set common
labels in news (e.g., anchor, 2anchor, text-scene, etc.).
These labels are then input to a HMM for the segmentation
task. They report best performances of 74.9% recall and
80.2% precision for the TRECVID dataset. The work of [4]
however remains limited due to the flat structure HMM, and
it is not clear how the set of `transition' states were chosen.
In an effort to move beyond flat structure, the authors of [4]
have raised the need for high-order statistical techniques,
which will be addressed in this paper through the HHMM
and S-HSMM.
More recent approaches towards scene extraction have
shifted to motion pictures (e.g., [30, 34, 1, 31]). Detecting
scenes in motion pictures is in general a challenging problem
and there are three main existing approaches as outlined
in [31]: temporal clustering-based, rule-based and memory-based
detection. In the clustering-based approach, shots are
grouped into scenes based on visual similarity and temporal
closeness (e.g., [8, 13]). Scene breaks in the rule-based
detection approach are determined based on the semantic
and syntactic analysis of audiovisual characteristics and in
some cases further enhanced with more rigorous grammars
from film theory (e.g., [34, 1]). The authors in [30] propose a
memory-based scene detection framework. Visual shot similarity
in these works is determined based on the consistency
in color chromaticality, and the soundtrack is partitioned
into `audio scenes'. Visual and aural data are then fused
within a framework of memory and attention span model to
find likely scene breaks or singleton events. Further related
background on scene detection can be found in many good
surveys (e.g., [30, 28, 31]).
Existing HMM-based approaches towards modeling long-term
temporal dependencies typically use pre-segmented training
data at multiple levels, and hierarchically train a pool
of HMMs, in which HMMs at the lower levels are used as
input to the HMMs at the upper levels. In principle, some
fundamental units are recognised by a sequence of HMMs,
and then likelihood values (or labels) obtained from these
HMMs are combined to form a hierarchy of HMMs
2
to capture
the interactions at higher semantic levels (e.g., [11,
18]). Analysing sports videos, Kijak et al. [11] propose a
two-tiered classification of tennis videos using two layers
of HMMs. At the bottom level, four HMMs are used to
model four shot classes (`first missed serve',`rally', `replay',
and `break'). Each HMM is trained separately and subse-quently
topped up by another HMM at the top level which
represents the syntax of the tennis video with three states
of the game: `sets', `games', and `points'. Parameters for
the top HMM are, however, all manually specified. In [18],
a generic two-level hierarchy of HMMs is proposed to detect
recurrent events in movies and talk shows. Their idea
is to use an ergodic HMM at the top level, in which each
state is another (non-ergodic) sub-HMM representing a type
of signal stationary properties. For the case of movies, the
top HMM has six states, and each is in turn another three-state
non-ergodic HMM. The observations are modelled as
a mixture of Gaussians. After training, the authors claim
that interesting events can be detected such as `explosion',
`male speech', and so on. While being able to overcome the
limitation of the flat HMM in modeling long-term dependencies
, approaches that use HMMs at multiple levels still
suffer from two major problems: (1) pre-segmented and an-notated
data are needed at all levels for training, and (2)
in most existing work parameterization at higher levels has
to be manually specified. In many cases, preparing training
data at multiple levels is extremely tedious and at worst,
may not be possible. With respect to the second problem,
since each semantic level has to be modeled separately, the
underlying problem is that the interactions across semantic
layers are not modeled and thus do not contribute to the
learning process.
One framework that integrates the semantics across layers
is the Hierarchical Hidden Markov Model (HHMM) proposed
recently in [6]. The hierarchical HMM extends the
standard HMM in a hierarchic manner to allow each state
to be recursively generalised as another sub-HMM, and thus
enabling the ability to handle hierarchical modeling of complex
dynamic processes, in particular "the ability to infer
correlated observations over long periods in the observation
sequence via the higher levels of hierarchy" [6]. The original
motivation in [6] was to seek better modeling of different stochastic
levels and length scales presented in language (e.g.,
speech, handwriting, or text). However, the model introduced
in [6] considers only state hierarchies that have tree
structures, disallowing the sharing of substructures among
the high-level states. Recognizing this need, the authors
in [3] have extended the strict tree-form topology in the
original HHMMs of [6] and allowed it to be a general lattice
structure. The extension thus permits a state at any arbitrary
level of the HHMMs to be shared by more than one
parental state at its higher level (i.e., resulting in a compact
form of parameter typing at multiple levels). This extended
2
Not to be confused with the Hierarchical HMMs.
13
form is very attractive for video content modeling since it
allows the natural organization of the video content to be
modeled not only in terms of multiple scales but also in
terms of shared substructures existing in the decomposition.
Further details on the HHMM are provided in Section 3.1.
Early application of the HHMM for video analysis is found
in [36] and later extended in [35]. In these works, the authors
use the HHMM to detect the events of `play' and
`break' in soccer videos. For inference and learning, the
HHMM is `collapsed' into a flat HMM with a very large
product state space, which can then be used in conjunction
with the standard forward/backward passes as in a normal
HMM. Four methods are compared in [36] to detect `play'
and `break': (1) supervised HMMs, in which each category
is trained with a separate HMM, (2) supervised HHMMs,
in which bottom level HMMs are learned separately and
parameters for the upper levels are manually specified, (3)
unsupervised HHMMs without model adaptation, and (4)
supervised HHMMs with model adaptation. In (3) and (4),
two-level HHMMs are used. Their results have shown a very
close match between unsupervised and supervised methods
in which the completely unsupervised method with model
adaptation performs marginally better. These figures are
75.5%, 75.0%, 75.0% and 75.7% respectively for those four
methods. While presenting a novel contribution to the feature
selection and model selection procedure, the application
of the HHMMs in this work is still limited both for learning
and for exploitation of the hierarchical structure. Flattening
a HHMM into a flat HMM as done in [36, 35] suffers from
many drawbacks as criticized in [17]: (a) it cannot provide
multi-scale interpretation, (b) it loses modularity since the
parameters for the flat HMM get constructed in a complex
manner, and (c) it may introduce more parameters, and
most importantly it does not have the ability to reuse parameters
, in other words parameters for the shared sub-models
are not `tied' during the learning, but have to be replicated
and thus lose the inherent strength of hierarchical modeling.
Being able to model shared structures, the extended HHMMs
of [3] allows us to build more compact models, which
facilitates more efficient inference and reduces the sample
complexity in learning. This model is applied in [20] and [22]
for the problem of topic transition detection and video structure
discovery respectively. The authors in [20] use a three-level
HHMM for the detection of topic transitions in educational
videos. Differing from our experiments in this paper
, the HHMM in [20] is modified to operate directly with
continuous-valued observed data via the use of Gaussian
mixture models as the emission probabilities. Each shot-based
observed vector consists of seven features extracted
from visual and audio streams. They report a 77.3% recall
rate and 70.7% precision for the detection task. In another
application, with the help of prior knowledge about educational
videos, a topology for a three-level HHMM is used
in [22] to automatically discover meaningful narrative units
in the educational genre. Their experiments have shown encouraging
results in which many meaningful structures are
hierarchically discovered such as `on-screen narration with
texts', `expressive linkage', `expressive voice-over', etc. The
work of [22] is somewhat similar to that of [18] reviewed
earlier in this section, except the model in [22] allows more
domain knowledge to be encoded and the parameters are all
learned automatically.
THE PROBABILISTIC TOPIC DETECTION FRAMEWORK
Our topic detection framework consists of two phases.
The first phase performs shot detection and low level feature
extraction and then classifies a shot in a meaningful label set
. This phase is described in Section 4. In the next phase,
we train a HHMM or S-HSMM over the alphabet space 
from the training data and then use it in conjunction with
the Viterbi to perform segmentation and annotation. The
architecture of the framework is depicted in Figure-1.
1
2
F
E
A
T
U
R
E
E
X
T
R
A
C
T
I
O
N
SHOT DETECTION AND
CLASSIFICATION
Direct Narration
Assisted Narration
Voice-Over
Expressive Linkage Functional Linkage
M-phase Coxian
M-phase Coxian
M-phase Coxian
M-phase Coxian
M-phase Coxian
END
`Intro'
`main body'
1
2
3
4
5
Video & Audio Signals
Figure 1: The architecture for topic detection framework.
The two-level HHMM and the S-HSMM (whose topology
is shown on the top of Figure-1) are special cases of
the hierarchical model with two layers. For the S-HSMM
(HHMM), the top layer is a Markov sequence of switching
variables, while the bottom layer is a sequence of concate-nated
HSMMs (HMMs) whose parameters are determined
by the switching variables at the top. Thus, the dynamics
and duration parameters of the HSMM (HMM) at the bottom
layer are not time invariant, but are `switched' from
time to time, similar to the way the linear Gaussian dynamics
are switched in a switching Kalman filter. When
mapping to the topic modeling problem, the bottom layer
is used to capture `atomic' semantics such as voice-over, expressive
linkage or assisted narration. Combinations of these
atomic semantics then form higher-level semantics, each of
which is represented by a hidden state at the top layer in
our model.
3.1 The Hierarchical HMM
With the assumed knowledge of the flat HMM (e.g., see [24]),
we shall now briefly describe the HHMMs. A hierarchical
HMM is formally defined by a three-turple , ,  : a topo-logical
structure  parameterized by  and an emission alphabet
space . The topology  specifies the model depth
D, the state space S
d
available at each level d, and the
parent-children relationship between two consecutive levels.
For example, the two-level topology shown on the top of
14
Figure-1 specifies the children set at the bottom level for
state 1 is {1, 2, 5} and for state 2 is {2, 3, 4}. Here, state 2
at the bottom level has been `shared' by both state 1 and
2 at the top level. Given , the parameter  of the HHMM
is specified in the following way. For d &lt; D, p  S
d
and
i, j  S
d+1
are the children of p:
d,p
i
is the initial probability
of i given p; A
d,p
i,j
is the transition probability from i
to j given the parent p; and A
d,p
i,end
is the probability that
state i going to end-state (i.e., returns control to its parent)
given the parent is p. Finally, for each state i at the lowest
level D and an alphabet v  : B
v|i
is the emission probability
of observing v given the current state at the lowest
level is i. The whole parameter set is written compactly as:
 = {, A, A
end
, B}, where:
=
[
1d&lt;D
pSd
n
d,p
: 1 × M o ,
B : |S
d
| × ||
A =
[
1d&lt;D
pSd
nA
d,p
: M × M o , A
end
=
[
1d&lt;D
pSd
nA
d,p
end
: 1 × M o
where in each each M is implicitly meant the number of children
of p and |.| is the cardinality operator. Stochastic constraints
require: P
i

d,p
i
= 1, P
v
B
v|i
= 1 and P
j
A
d,p
i,j
+
A
d,p
i,end
= 1. An intuitive way to view the set  is to consider
the subset {
d,p
, A
d,p
, A
d,p
end
} as the parameter of the
p-initiated Markov chain at level d. This chain is terminated
when one of the children i of p reaches the end-state with the
probability of A
d,p
i,end
. For inference and learning, the HHMM
is represented as a dynamic Bayesian network (DBN) and
can be learned by the Asymmetric Inside-Outside algorithm
in [3] or by the forward/backward passes in [17]. Figure-3
shows on its left the DBN representation of the HHMM
with two levels, i.e., D = 2. We refer readers to [6, 17, 3]
for further information on the HHMMs.
3.2 The Switching-Hidden Semi Markov Model
To provide an intuitive view to the S-HSMM, starting
from the description of the HHMMs from the previous section
, let us consider the case of a two-layer HHMM (D = 2)
defined as follows. The state space is divided into the set of
states at the top level Q

= S
1
= {1, . . . , |Q

|} and states
at the bottom level Q = S
2
= {1, . . . , |Q|}. This model is
parameterized by  = {

, A

, , A, A
end
, B}.
At the top level,

p
and A

pq
are respectively the initial
probability and the transition matrix of a Markov chain defined
over the state space Q

. For each p  Q

, ch(p)  Q is
used to denote the set of children of p. As in the case of the
extended HHMM in [3], it is possible that different parent
states may share common children, i.e., ch(p)  ch(q) =  for
p, q  Q

. A transition to p at the top level Markov chain
will initiate a sub-Markov chain at the lower level over the
state space ch(p) parameterized by {
p
, A
p
, A
p
end
} where
q
i
and A
p
ij
are the initial and transition probabilities as in the
normal HMM setting, and A
p
i,end
is the probability that this
chain will terminate after a transition to i. At each time
point t, a discrete symbol y
t
is generated with a probability
of B
v|i
where i is the current state at the bottom
level. In the description of this two-level HHMM, the duration
d for which a bottom state i remains the same clearly
has a geometric distribution parameterized by its non-self-transition
probability (1 - A
p
ii
), i.e., d  Geom(1 - A
p
ii
).
In many cases, the geometric distributions are often too
restricted to model realistic data. The Switching Hidden
Semi-Markov Models (S-HSMMs) proposed in [5] overcomes
this restriction and allows the duration d of state i at the
bottom level to follow a more general discrete distribution
d  D
p,i
d
. More precisely, the p-initiated chain at the bottom
level is now a semi-Markov sequence parameterized by
{
p
i
, A
p
ij
, D
p,i
d
} as opposed to the normal Markov chain in the
HHMM case. The authors in [5] consider two families of distributions
for modeling the duration: the multinomial and
the Coxian. However for the multinomial case, the complexity
of the learning algorithm is proportional to the maximum
duration length, thus making it unsuitable for the problem
of modeling video data which is usually very long in nature.
Apart from the disadvantage of assuming a maximum duration
, our empirical testing on the multinomial case with
the maximum length of 50 has also shown that it is about
20 times slower than its Coxian counterpart reported in this
paper, thus making it impractical in our settings. We will
therefore omit the multinomial case and will consider exclu-sively
the Coxian parameterization in this paper.
A discrete M -phase Coxian distribution Cox(µ; ), parameterized
by µ = {µ
1
, . . . , µ
M
} (P
i
µ
i
= 1) and  =
{
1
, . . . ,
M
}, is defined as a mixture of P
M
i=1
µ
i
S
i
where
S
i
(X
i
+ . . . + X
M
), in which X
i
are independent random
variables having geometric distributions X
i
Geom(
i
).
This distribution is a member of the phase-type distribution
family and has the following very appealing interpretation
. Let us construct a Markov chain with M + 1 states
numbered sequentially with the self transition parameter
A
ii
= 1 i
as shown in Figure-2. The first M states rep-1
absorbing
state
2
M
1
M

2

M

1
µ
M
µ
2
µ
1

Figure 2: The phase diagram of an M -phase Coxian.
resent M phases, while the last is the absorbing state which
acts like an end state. The duration of each individual state
(phase) i is X
i
Geom(
i
). If we start from state i, the
duration of Markov chain before the end state reached is
S
i
= X
i
+ . . . + X
M
. Thus, Cox(µ, ) is indeed the distribution
of the duration of this constructed Markov chain with µ
as the initial state (phase) distribution. The discrete Coxian
is much more flexible than the geometric distribution:
its probability mass function is no longer monotonically decreasing
and it can have more than one mode.
Using the Coxian distribution, the duration for the states
at the bottom level in the S-HSMM is modeled as follows.
For each p-initiated semi-Markov sequence, the duration of a
child state i is distributed according to D
p,i
d
= Cox(d; µ
p,i
,
p,i
).
The parameter µ
p,i
and
p,i
are M -dimensional vectors
where M is a fixed number representing the number of phases
in the discrete Coxian. It is easy to verify that for M = 1,
the model reduces identically to a two-layer HHMM.
15
3.3 Inference and Learning in the S-HSMM
For inference and learning, the S-HSMM is represented as
a dynamic Bayesian network as shown in Figure-3 and then
forward/backward passes are applied to compute the filtering
and smoothing distributions required for EM learning.
t
+1
t
z
t
z
t
+1
m
t
m
t
+1
y
t
y
t
+1
x
t
+1
x
t
e
t
+1
e
t
z
t
z
t
+1
y
t
y
t
+1
x
t
+1
x
t
t
t
+1
e
t
e
t
+1
Figure 3: Two-slice DBN representation of a two-level
HHMM (left) and the (Coxian) S-HSMM (right).
At each time-slice t, an amalgamated hidden state S
t
=
{z
t
,
t
, x
t
, e
t
, m
t
} together with the observation y
t
are maintained
. The top level state is updated via z
t
and
t
is a
boolean-valued variable set to 1 when the z
t
-initiated semi-Markov
sequence ends at t. At the bottom level, x
t
is the
current child state in the z
t
-initiated chain, m
t
represents
the current phase of x
t
and e
t
is a boolean-valued variable
set to 1 when x
t
reaches the end of its duration. The forward
and backward procedures in the general DBN are then used
to compute the filtering distribution Pr(S
t
|y
1:t
) and two
smoothing distributions Pr(S
t
|y
1:T
) and Pr(S
t
, S
t+1
|y
1:T
).
With these smoothing distributions, it is sufficie