Black-Box Constructions for Secure Computation
ABSTRACT
It is well known that the secure computation of non-trivial
functionalities in the setting of no honest majority requires
computational assumptions. We study the way such computational
assumptions are used. Specifically, we ask whether
the secure protocol can use the underlying primitive (e.g.,
one-way trapdoor permutation) in a black-box way, or must
it be nonblack-box (by referring to the code that computes
this primitive)? Despite the fact that many general constructions
of cryptographic schemes (e.g., CPA-secure encryption
) refer to the underlying primitive in a black-box
way only, there are some constructions that are inherently
nonblack-box. Indeed, all known constructions of protocols
for general secure computation that are secure in the presence
of a malicious adversary and without an honest majority
use the underlying primitive in a nonblack-box way
(requiring to prove in zero-knowledge statements that relate
to the primitive).
In this paper, we study whether such nonblack-box use
is essential. We present protocols that use only black-box
access to a family of (enhanced) trapdoor permutations or
to a homomorphic public-key encryption scheme. The result
is a protocol whose communication complexity is independent
of the computational complexity of the underlying
primitive (e.g., a trapdoor permutation) and whose computational
complexity grows only linearly with that of the
underlying primitive. This is the first protocol to exhibit
these properties.
Categories and Subject Descriptors
F.1.2 [Theory of
Computation]: Interactive and reactive computation
Research supported by grant 36/03 from the Israel Science
Foundation.

Department of Computer Science, Technion, Israel. email:
{yuvali,eyalk,erez}@cs.technion.ac.il

Department of Computer Science, Bar-Ilan University, Israel
. email: lindell@cs.biu.ac.il. Much of this work was
carried out while the author was visiting the Technion.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
STOC'06, May
21Â­23, 2006, Seattle, Washington, USA.
Copyright 2006 ACM 1-59593-134-1/06/0005 ...
$
5.00.
General Terms
Algorithms, Theory

INTRODUCTION
It is a known fact that most cryptographic tasks require
the use of computational hardness assumptions. These assumptions
typically come in two types: specific assumptions
like the hardness of factoring, RSA, discrete log and others,
and general assumptions like the existence of one-way functions
, trapdoor permutations and others. In this paper, we
refer to general assumptions and how they are used. Specifically
, we consider an intriguing question regarding how secure
protocols utilize a primitive that is assumed to carry
some hardness property. Here again, there is a clear distinction
between two types of uses:
1. Black-box usage: a protocol (or construction) uses
a primitive in a black-box way if it refers only to the
input/output behavior of the primitive.
1
For example,
if the primitive is a trapdoor permutation, then the
protocol may sample a permutation and its domain,
and may compute the permutation and its inverse (if
the trapdoor is given). Beyond this, no reference is
made to the primitive. In particular, the code used to
compute the permutation (or carry out any other task)
is not referred to by the protocol. The vast majority
of constructions in cryptography are black-box.
2. Nonblack-box usage: a protocol (or construction)
uses a primitive in a nonblack-box way if it refers to
the code for computing its functionality. A typical example
of a nonblack-box construction is where a Karp
reduction is applied to the circuit computing the function
, say, in order to prove an
N P zero-knowledge
proof, as in [14].
A rich and fruitful body of work, initiated by [16], attempts
to draw the borders between possibility and impossibility for
black-box constructions in cryptography. While many of the
relations between primitives are well understood, there are
still some important tasks for which the only constructions
that we have rely on nonblack-box access to the assumed
primitive, yet the existence of a black-box construction is
1
It is typically also required that the security proof of the construction
is black-box in the sense that an adversary breaking the protocol
can be used as an oracle in order to break the underlying primitive.
See, e.g., [11, 12, 29] for a comprehensive treatment of black-box reductions
in cryptography.
99
not ruled out. In particular, all known general constructions
of multiparty protocols that are secure in the presence
of malicious adversaries and without an honest majority
, originating from [15], use nonblack-box access to the
assumed primitive.
2
(We note that by "general construc-tions"
, we mean constructions that can be used to securely
compute any functionality.)
Another notable example of
this phenomenon is the case of public-key encryption that
is secure against chosen-ciphertext attacks [7, 30, 23]; here
too, all known constructions are nonblack-box. The above
phenomenon begs the following question:
Is it possible to construct general protocols for
secure computation without an honest majority
and with malicious adversaries, given only black-box
access to a "low-level" primitive?
Answering the above question is of interest for the following
reasons. First, it is of theoretical interest to understand
whether or not nonblack-box access to a primitive is necessary
for these tasks. An answer to this question would
enhance our understanding of how hardness assumptions
can (or must) be used. Second, as we have mentioned, the
nonblack-box use of the underlying primitive is typically utilized
in order to apply a Karp reduction for the purpose
of using a (general) zero-knowledge proof. Such reductions
are highly inefficient and are unlikely to be very useful in
practice. Furthermore, in these protocols the communication
complexity depends on the complexity of computing
the primitive and the computational complexity grows more
than linearly with that of the primitive. (An exception to
this rule is the communication-efficient compiler presented
in [26], which relies on the communication-efficient arguments
of [20, 25]. However, the computational complexity
of the protocol of [26] is even worse than the GMW protocol
[15].)
To illustrate the type of inefficiency resulting from current
nonblack-box constructions, consider the following hypothetical
scenario. Suppose that, due to major advances
in cryptanalytic techniques, the security parameter must
be large enough so that all basic cryptographic primitives
require a full second of computation on a fast CPU. In
such a case, would it still be possible to carry out a distributed
task like oblivious transfer? Current nonblack-box
techniques (e.g., the GMW protocol [15]) require parties to
prove in zero-knowledge statements that involve the computation
of the underlying primitive, say a trapdoor permutation
. These zero-knowledge protocols, in turn, invoke
cryptographic primitives for any gate of a circuit computing
a trapdoor permutation. Since (by our assumption) a trapdoor
permutation takes one second to compute, its circuit
implementation contains trillions of gates, thereby requiring
the protocol trillions of second to run. In contrast, a
black-box construction of oblivious transfer from the trapdoor
permutation primitive would make the number of invocations
of the primitive independent of the complexity of
2
We stress that the above discussion is only true when considering
general assumptions. Furthermore, it is only true when considering
"low-level primitives" like trapdoor permutations. Specifically, there
do exist constructions of secure multiparty protocols that use only
black-box access to an oblivious transfer primitive [18].
However,
since it is not known how to construct oblivious transfer using only
black-box access to, say trapdoor permutations, the overall construction
obtained does not use its "low-level" primitive in a black-box
way.
implementing the primitive, thus making oblivious transfer
feasible even in the hypothetical scenario described above.
We conclude that the current nonblack-box use of the underlying
primitives constitutes an obstacle to efficiency. It is
therefore of great interest to know whether or not it is possible
to obtain solutions to these tasks that do not suffer from
this obstacle. (We note that the inefficiency of nonblack-box
constructions here is quite ironic because in many areas of
cryptography, black-box constructions have been shown to
have inherent computational limitations [21, 10].) Despite
the above, we stress that the focus of this paper is not on
efficiency, but rather on the theoretical question of whether
or not it is possible to obtain the aforementioned black-box
constructions. We believe this question to be interesting in
its own right.
Our results.
We show how to construct general secure
multiparty computation (for the case of no honest majority
and malicious adversaries), given black-box access to either
homomorphic encryption schemes or enhanced trapdoor permutations
(see [13, Appendix C.1] for the definition of enhanced
trapdoor permutations). We note that all known
general constructions for this task from "low-level" primitives
rely on either enhanced trapdoor permutations or homomorphic
encryption schemes. However, they all use them
in an inherently nonblack-box way. This is the case even for
protocols that implement very simple functionalities, such
as oblivious transfer. We prove the following:
Theorem 1.1. There exist protocols for securely computing
any multiparty functionality without an honest majority
and in the presence of static malicious adversaries, that rely
only on black-box access to a family of enhanced trapdoor
permutations or to a homomorphic encryption scheme.
We remark that nonblack-box access is not typically used
when considering semi-honest adversaries [32, 15]. Rather,
the nonblack-box access is utilized in known protocols in order
to have the parties prove (in zero-knowledge) that they
are correctly following the protocol specification. This is
necessary for preventing a malicious adversary from effec-tively
deviating from the protocol instructions. We note also
that in the case of an honest majority, it is possible to securely
compute any functionality information-theoretically,
and without any hardness assumption [2, 5]. Thus, no primitive
at all is needed. For this reason, we focus on the case
of no honest majority (including the important two-party
case) and malicious adversaries.
Techniques.
In order to prove Theorem 1.1, we begin
by constructing oblivious transfer protocols that use only
black-box access to enhanced trapdoor permutations or homomorphic
encryption schemes, but provide rather weak security
guarantees. We then "boost" the security of these
protocols in order to obtain protocols that are secure in the
presence of malicious adversaries. Constructions until today
that have followed this paradigm work by first obtaining
protocols that are secure in the presence of semi-honest
adversaries, and then boosting them so that they are secure
in the presence of malicious adversaries. However, it is
not known how to carry out this "boosting" in a black-box
way (and, indeed, it has been conjectured that malicious
oblivious transfer cannot be constructed from semi-honest
oblivious transfer in a black-box way [24]). Since we wish to
make our construction black-box, we take a different route.
100
Protocol number
Security for corrupted sender
Security for corrupted receiver
3.1, 3.3
Private for defensible sender
Private for defensible receiver
4.1
Private for defensible sender
Secure for malicious receiver
5.1
Secure for malicious sender
Private for defensible receiver
In Theorem 6.1
Secure for malicious sender
Secure for malicious receiver
Table 1: The progression of our constructions: each protocol uses the previous one as a subprotocol.
Specifically, we begin by introducing the notion of a defensible
adversary. In order to describe this notion, we describe
what a defense is: a defense is an input and random-tape
that is provided by the adversary after the protocol execution
concludes. A defense is good if the honest party upon
that input and random-tape would have sent the same messages
as the adversary sent. Such a defense is a supposed
"proof" of honest behavior. However, the adversary need
not actually behave honestly and can construct its defense
retroactively (after the execution concludes). A protocol is
said to be private in the presence of defensible adversaries if
privacy is preserved in the event that an adversary provides
a good defense. However, in the case that the adversary
doesn't provide a good defense, nothing is guaranteed, and
the entire honest party's input may be learned. This notion
is therefore rather weak. We note that the oblivious transfer
protocol of [8] is not secure under this notion. However, it
can be efficiently modified into one that is secure under this
notion. It is also possible to efficiently construct such an
oblivious transfer protocol from homomorphic encryption.
Importantly, we show that it is possible to construct oblivious
transfer that is secure in the presence of malicious adversaries
from oblivious transfer that is private in the presence
of defensible adversaries. Furthermore, this construction is
black-box.
As we have mentioned, we start by constructing oblivious
transfer protocols that are private in the presence of
defensible adversaries. We present two such protocols: one
that uses black-box access to a family of enhanced trapdoor
permutations, and one that uses black-box access to a homomorphic
public-key encryption scheme. Next, we construct
from the above oblivious transfer protocol a new oblivious
transfer protocol that is still private in the presence of defensible
senders, but is secure in the presence of malicious
receivers (where security is "full security" according to the
ideal/real simulation paradigm). This is achieved using the
so-called cut-and-choose technique. That is, many oblivious
transfer executions (using random inputs) are run, and the
receiver is asked to present a defense for its behavior in half
of them. If it indeed presents a good defense, then we are
guaranteed that it behaved somewhat honestly in most of
the executions.
We stress that this step is novel, because the requirements
on a protocol that is secure according to the ideal/real simulation
paradigm are much stricter than when only privacy
is guaranteed. Indeed, some efficient protocols for oblivious
transfer from the literature [27, 1, 17] are private for both
(malicious) parties, but are not fully secure for either party.
Nevertheless, we are able to boost both the resilience of the
protocol (from a defensible to a malicious adversary) and
its security guarantee (from privacy to full simulation-based
security). Next, we "reverse" the oblivious transfer protocol
(i.e., by switching the sender and receiver roles) in order to
obtain a protocol with reversed security properties. Specifically
, this next protocol is secure in the presence of malicious
senders and private in the presence of defensible receivers.
At this point, we reapply our security boosting technique in
order to obtain a protocol that is "fully secure"; that is, a
protocol that is secure in the presence of malicious senders
and receivers. See Table 1 for the series of oblivious transfer
protocols that we construct. Needless to say, each protocol
uses its subprotocol in a black-box way.
Finally, having constructed secure oblivious transfer protocols
using only black-box access to primitives, it suffices to
apply the well-known result of Kilian [18, 19] that shows that
any functionality can be securely computed using black-box
access to a secure oblivious transfer protocol. This therefore
yields Theorem 1.1, as desired.
Related work. Recently, in [6], it was shown that it is possible
to construct constant-round protocols for the setting of
an honest majority, that use only black-box access to the assumed
primitive. As we have mentioned, in the setting of
an honest majority, it is possible to construct information-theoretically
secure protocols (which are, by triviality, black-box
). Nevertheless, there are no known (general) constant-round
protocols for the information-theoretic setting, and
so [6] relates to this issue. We remark that the techniques
used in [6] and here are vastly different, due to the inherent
differences between the setting of an honest majority and
that of no honest majority.
Organization.
Due to lack of space in this abstract, we
present only brief sketches of the definitions and proofs.
Complete details appear in the full version of the paper.
We often write OT as shorthand for oblivious transfer.
DEFINITIONS
We denote by
P
1
(1
n
, x
1
,
1
)
, P
2
(1
n
, x
2
,
2
) the transcript
of an execution between parties
P
1
and
P
2
with a security
parameter
n, where P
i
has input
x
i
and random-tape

i
. For
brevity, we will sometimes omit the security parameter 1
n
.
The message sent by party
P
i
(on the above inputs) after
having received the series of incoming messages
is denoted
by
P
i
(
x
i
,
i
;
). Stated otherwise, P
i
(
x
i
,
i
;
Â·) denotes the
next message function of
P
i
. Let
t = P
1
(
x
1
,
1
)
, P
2
(
x
2
,
2
) .
Then, denote the
th
message sent by
P
i
in
t by sent
P
i
(
t) and
the first
messages received by
P
i
in
t by received
P
i
1,...,
(
t).
We also denote the output of
P
i
in an execution by
output
P
i
P
1
(
x
1
,
1
)
, P
2
(
x
2
,
2
) .
In our presentation, we assume familiarity with the standard
definitions of secure computation; see [13, Chapter 7]
for a full treatment. In this work, we consider malicious adversaries
(i.e., adversaries that may arbitrarily deviate from
the protocol specification), and static corruptions (meaning
that the set of corrupted parties is fixed before the protocol
execution begins).
We use a non-uniform formulation of adversaries here and
therefore, without loss of generality, assume that they are
101
deterministic. However, this is not essential and all of our
proofs hold for the uniform model of computation.
Black-box access to primitives. In this paper, we consider
constructions of protocols that use only black-box access
to an underlying primitive. This can be easily formalized
by defining oracles that provide the functionality of the
primitive. For example, a trapdoor permutation can be defined
by an oracle that samples a function description along
with a trapdoor, an oracle that is given the function description
and samples a random value from the domain, an
oracle that is given the function description and a point in
the domain and computes the permutation, and an oracle
that is given the trapdoor and a point in the domain and
computes the permutation inverse. It is easy to see that
our protocols rely on the underlying primitive in a black-box
way. We will therefore not burden the presentation by
formally defining these oracles. We remark that we also construct
protocols that use subprotocols in a black-box way.
This can be formalized by just looking at the input/output
behavior of the protocol. We will not formalize this. It suffices
for our result to note that if the subprotocol uses the
underlying primitive in a black-box way, then the protocol
(that uses the subprotocol) also uses the underlying primitive
in a black-box way. Again, this is easy to verify for
all of our protocols. In addition to using the underlying
primitive in a black-box way, our proofs of security are also
black-box. Therefore, our reductions are what are typically
called "fully black-box" [29].
2.2
Defensible Adversarial Behavior
We introduce the notion of defensible adversarial behavior
. Loosely speaking, an adversary that exhibits defensible
behavior may arbitrarily deviate from the protocol specification
. However, at the conclusion of the protocol execution,
the adversary must be able to justify or defend its behavior
by presenting an input and a random-tape such that the
honest party (with this input and random-tape) would behave
in the same way as the adversary did. A protocol is
"private" under defensible adversarial behavior if it is "private"
in the presence of such adversaries. We stress that if
an adversary behaves maliciously and cannot provide a good
defense, then no security guarantees are given.
We now define the notion of a good defense. Intuitively,
a defense is an "explanation" of an adversary's behavior
during the protocol execution. Such an explanation consists
of an input and random-tape, and the defense is "good" if
an honest party, given that input and random-tape, would
have sent the same messages as the adversary did during the
protocol execution. The formal definition follows.
Definition 2.1. (good defense for t): Let t be the transcript
of an execution of a protocol
= (P
1
, P
2
) between an
adversary
A (say, controlling P
1
) and the honest party (say
P
2
). Then, we say that the pair (
x
1
,
1
) constitutes a good
defense by
A for t in , denoted (x
1
,
1
) = defense

A
(
t), if for
every
it holds that sent
A
(
t) = P
1
(
x
1
,
1
; received
A
1,..., -1
(
t)).
In other words, every message sent by
A in the execution
is such that the honest party
P
1
with input (
x
1
,
1
) would
have sent the same message.
2.3
Security of OT Protocols
The starting point of our constructions is an oblivious
transfer protocol [28, 8] that is private in the presence of a
defensible receiver or sender. Recall that an oblivious transfer
protocol involves a sender
S with two input strings s
0
and
s
1
, and a receiver
R with an input bit r  {0, 1}. Very
informally, an oblivious transfer protocol has the property
that the sender learns nothing about the receiver's bit
r and
the receiver obtains
s
r
, but learns nothing about
s
1-r
. (The
variant of oblivious-transfer that we use here is usually referred
to as "1-out-of-2 OT".) We begin by presenting the
formal definition of oblivious transfer that is private in the
presence of a defensible receiver and then proceed to define
privacy in the presence of a defensible sender.
Non-trivial protocols.
One technicality that must be
dealt with is that a protocol that does nothing is trivially
"private" in that it does not reveal anything about the par-ties'
inputs. Of course, such a protocol is also useless. In
order to make sure that the oblivious transfer protocols that
we construct are "useful", we define the notion of a non-trivial
oblivious transfer protocol. Such a protocol has the
property that if both the sender and receiver are honest,
then the receiver will receive its output as designated by
the oblivious transfer functionality
f((s
0
, s
1
)
, r) = (, s
r
)
(where
denotes the empty output).
Privacy for random inputs in the presence of a defensible
receiver.
We now define privacy for defensible
receivers. Recall that the receiver in an oblivious transfer
protocol is supposed to obtain one of the pair (
s
0
, s
1
) in the
execution. However, the other value must remain secret.
When considering defensible adversaries, the requirement is
that, as long as the adversary can provide a good defense,
it can only learn one of the values. Recall that, by Definition
2.1, a party's defense includes its input (in this case, the
bit
r of the receiver, meaning that it wishes to obtain the
value
s
r
). We therefore require that a defensible receiver can
learn nothing about
s
1-r
when its defense contains the input
value
r. Due to technical reasons in our proofs later on,
we define privacy only for the case that the sender's inputs
are uniformly distributed bits. Fortunately, this will suffice
for our constructions.
We define an experiment for a protocol
and an adversary
A modelled by a polynomial-size family of circuits {A
n
}
nN
.
Informally, the experiment begins by choosing a random pair
of bits (
s
0
, s
1
) to be used for the sender's input. The adversary's
aim is to guess the value of the input that it doesn't
receive as output.
Experiment Expt
rec

(
A
n
):
1. Choose
s
0
, s
1

R
{0, 1} uniformly at random.
2. Let

S
be a uniformly distributed random tape for
S
and let
t = S(1
n
, s
0
, s
1
,
S
)
, A
n
.
3. Let ((
r,
r
)
, ()) be the output of A
n
(
t). (The pair
(
r,
r
) constitute
A
n
's defense and
is its guess for
s
1-r
.)
4. Output 1 if and only if (
r,
r
) is a good defense by
A
n
for
t in , and  = s
1-r
.
Notice that by
A's defense, it should have received s
r
. The
challenge of the adversary is therefore to guess the value
of
s
1-r
; if it cannot do this, then the sender's privacy is
preserved.
102
Definition 2.2. (privacy for random inputs in the presence
of a defensible receiver): Let
= (S, R) be a non-trivial
oblivious transfer protocol. We say that
is private for random
inputs in the presence of a defensible receiver if for every
polynomial-size family of circuits
A = {A
n
}
nN
controlling
R, for every polynomial p(Â·) and for all sufficiently large n's
Pr [Expt
rec

(
A
n
) = 1]
&lt; 12 + 1
p(n) .
Remark. The definition of Expt
rec

only considers the case
that the inputs of the sender are uniformly distributed. We
stress that this is a very weak definition. However, the reasons
that we make this restriction are because (a) it suffices
for our construction of "fully secure" oblivious transfer
(see Protocol 4
.1), and more importantly, (b) without this
restriction we were unable to prove the privacy of Protocol
3
.3 for defensible receivers (see Section 3.2). We stress
that this restriction is not made when considering security
in the presence of malicious parties.
Privacy in the presence of a defensible sender.
In
an oblivious transfer protocol, the sender is not supposed to
learn anything about the receiver's input. When considering
a defensible sender, this means that the sender should
not be able to simultaneously present a good defense of its
behavior and make a correct guess as to the value of the receiver's
input. We stress that this privacy requirement only
needs to hold when the sender outputs a good defense; in
all other cases, there may be no privacy whatsoever. The
exact definition is formulated in a similar way as above.
Security.
The definitions above refer only to "privacy",
meaning that the adversary can learn nothing more about
the honest party's input than what is revealed by the output.
However, these definitions say nothing about the simulata-bility
of the protocols in question. In particular, a protocol
that is private by one of the above definitions may not
be secure according to the real/ideal simulation paradigm
(see [13, Chapter 7] for these definitions). When we mention
security in this paper, we refer to security according to
the ideal/real model paradigm.
PRIVACY FOR DEFENSIBLE SENDERS AND DEFENSIBLE RECEIVERS
In this section we show how to construct oblivious transfer
protocols that are private for defensible senders and receivers
. We present two protocols: one based on homomorphic
encryption and one based on enhanced trapdoor permutations
. Importantly, both protocols access the underlying
primitive in a black-box way only.
3.1
Bit OT from Homomorphic Encryption
We assume the existence of a public-key encryption scheme
(
G, E, D) that is indistinguishable under chosen-plaintext
attacks and has the following homomorphic property:
1. The plaintext is taken from a finite Abelian group
determined by the public key. For notational convenience
, we assume here that the group is an "additive"
group
Z
q
; however, the same construction works for
"multiplicative" groups as well.
2. Given any public-key
pk generated by the key generation
algorithm
G and any two ciphertexts c
1
=
E
pk
(
m
1
) and
c
2
=
E
pk
(
m
2
), it is possible to efficiently
compute a random encryption of the sum
E
pk
(
m
1
+
m
2
).
Consequently, it is also possible to efficiently
compute
E
pk
(
Â· m
1
) for any known integer
.
We also assume that (
G, E, D) has no decryption errors.
Such encryption schemes can be constructed under the quadratic
-residuosity, decisional Diffie-Hellman and other assumptions
; see [1, 17] for some references. The following protocol
is implicit in [22].
Protocol 3.1.
Â· Inputs: The sender S has a pair of bits (s
0
, s
1
); the
receiver
R has a bit r.
Â· The protocol:
1. The receiver
R chooses a pair of keys (pk, sk)
G(1
n
), computes
c = E
pk
(
r) and sends c and p
k
to
S.
2. The sender
S uses the homomorphic property and
its knowledge of
s
0
and
s
1
to compute a random
encryption
c = E
pk
((1
- r)s
0
+
rs
1
).
3.
R computes and outputs s
r
=
D
sk
(
c ).
Before proving security, note that if
S and R are both
honest, then
R receives the correct output. For example, if
r = 0, then c = E
pk
(1
Â· s
0
+ 0
Â· s
1
) =
E
pk
(
s
0
) and so
R
receives the correct value after decryption.
Claim 3.2. Assume that the encryption scheme (G, E, D)
is indistinguishable under chosen-plaintext attacks and has
no decryption errors. Then, Protocol 3
.1 is a non-trivial
oblivious transfer protocol that is private in the presence of
defensible senders and private for random inputs in the presence
of defensible receivers.
Privacy in the presence of a defensible (or even malicious)
sender follows from the fact that the sender's view consists
only of a single encryption under
E, and this encryption
is secure. Privacy with respect to a defensible receiver follows
since the existence of a proper defense implies that
c
is indeed an encryption of 0 or 1. This, in turn, guarantees
that
c is a random encryption of s
r
. Hence, again, privacy
follows from the security of
E.
3.2
Bit OT from Enhanced Trapdoor Permutations
The following protocol is a modified version of [8] that is
private in the presence of defensible adversaries. We stress
that the original protocol of [8] is completely insecure in the
presence of defensible adversaries.
The construction uses
any family of enhanced trapdoor permutations. Informally
speaking, a family of trapdoor permutations is comprised of
a function-sampling algorithm
I, a domain-sampling algorithm
D
f
, an algorithm
F for computing the permutation
and an algorithm
F
-1
for inverting the permutation (given
the trapdoor). Such a family is called enhanced if it is hard
to invert a random value
y even when given the coins used
by the domain-sampling algorithm to sample
y. See [13,
Appendix C.1 and Section 7.3] for a full definition. In the
sequel, we will abuse notation and refer to the random coins
used by
D
f
as its input. We note that the enhanced property
103
is used in all constructions of oblivious transfer from trapdoor
permutations. Indeed it has been shown that black-box
constructions of oblivious transfer from plain trapdoor permutations
is impossible [9].
We will require that
I is errorless, meaning that for every
series of random coins provided to
I, the description of
the function output is indeed a permutation. We call this
errorless function sampling, or just errorless sampling.
The protocol uses a perfectly binding commitment scheme
C. We denote a commitment to a using randomness  by
C(a; ). For simplicity, we assume that in order to commit
to a string
a of length n, it suffices to use a random string
that is also of length
n. Such a commitment scheme can be
obtained using black-box access to any trapdoor permutation
or homomorphic encryption scheme.
Protocol 3.3.
Â· Inputs: The sender S has a pair of random bits (s
0
, s
1
);
the receiver
R has a bit r.
Â· Auxiliary information: The description of a family
of (enhanced) trapdoor permutations (
I, D
f
, F, F
-1
) and
a hard-core bit
B for the family.
Â· The protocol:
1. The receiver
R chooses
1
,
R
{0, 1}
n
and sends
c = C(
1
;
) to the sender S.
2.
S chooses a trapdoor permutation pair (i, t)
I(1
n
) and a random

2

R
{0, 1}
n
, and sends
i
and

2
to
R.
3.
R computes y
1-r
=
D
f
(

1

2
); i.e.,
y
1-r
is
obtained by running the domain sampling algorithm
with coins

1

2
. In addition,
R chooses

R
{0, 1}
n
, obtains
x
r
=
D
f
(
) and computes
y
r
=
f
i
(
x
r
). Finally,
R sends (y
0
, y
1
) to
S.
4.
S uses t to compute
0
=
B(f
-1
i
(
y
0
))
s
0
and

1
=
B(f
-1
i
(
y
1
))
s
1
.
S sends (
0
,
1
) to
R.
5.
R computes and outputs s
r
=
B(x
r
)

r
.
Note that the only difference between Protocol 3.3 and
the protocol of [8] is that in [8], the value
y
1-r
is chosen
singlehandedly by the receiver,