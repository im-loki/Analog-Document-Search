Indexing Multi-Dimensional Time-Series with Support for Multiple Distance Measures
ABSTRACT
Although most time-series data mining research has concentrated
on providing solutions for a single distance function,
in this work we motivate the need for a single index structure
that can support multiple distance measures. Our specific
area of interest is the efficient retrieval and analysis of trajectory
similarities. Trajectory datasets are very common
in environmental applications, mobility experiments, video
surveillance and are especially important for the discovery
of certain biological patterns. Our primary similarity measure
is based on the Longest Common Subsequence (LCSS)
model, that offers enhanced robustness, particularly for noisy
data, which are encountered very often in real world applications
. However, our index is able to accommodate other distance
measures as well, including the ubiquitous Euclidean
distance, and the increasingly popular Dynamic Time Warping
(DTW). While other researchers have advocated one or
other of these similarity measures, a major contribution of
our work is the ability to support all these measures without
the need to restructure the index. Our framework guarantees
no false dismissals and can also be tailored to provide
much faster response time at the expense of slightly reduced
precision/recall. The experimental results demonstrate that
our index can help speed-up the computation of expensive
similarity measures such as the LCSS and the DTW.
Categories and Subject Descriptors
H.2.8 [Database Management
]: Database Applications, Data Mining
INTRODUCTION
In this work we present an efficient and compact, external
memory index for fast detection of similar trajectories. Trajectory
data are prevalent in diverse fields of interest such
as meteorology, GPS tracking, wireless applications, video
tracking [5] and motion capture [18]. Recent advances in
mobile computing, sensor and GPS technology have made it
possible to collect large amounts of spatiotemporal data and

The research of this author was supported by NSF ITR 0220148, NSF
CAREER 9907477, NSF IIS 9984729, and NRDRP
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee. SIGKDD '03, August 24-27, 2003, Washington,
DC, USA.
Copyright 2003 ACM 1-58113-737-0/03/0008...
$
5.00.
there is increasing interest in performing data analysis tasks
over such data [17]. In mobile computing, users equipped
with mobile devices move in space and register their location
at different time instances to spatiotemporal databases
via wireless links. In environmental information systems,
tracking animals and weather conditions is very common
and large datasets can be created by storing locations of observed
objects over time. Human motion data generated by
tracking simultaneously various body joints are also multidimensional
trajectories. In this field of computer graphics
fundamental operations include the clustering of similar
movements, leading to a multitude of applications such as interactive
generation of motions [2]. Spatiotemporal data are
also produced by migrating particles in biological sciences,
where the focus can be on the discovery of subtle patterns
during cellular mitoses [19]. In general, any dataset that
involves storage of multiple streams (attributes) of data can
be considered and treated as a multidimensional trajectory.
One very common task for such data is the discovery of
objects that follow a certain motion pattern, for purposes
of clustering or classification. The objective here is to efficiently
organize trajectories on disk, so that we can quickly
answer k-Nearest-Neighbors (kNN) queries. A frequent obstacle
in the analysis of spatiotemporal data, is the presence
of noise, which can be introduced due to electromagnetic
anomalies, transceiver problems etc. Another impediment
is that objects may move in a similar way, but at different
speeds. So, we would like our similarity model to be robust
to noise, support elastic and imprecise matches.
Choosing the Euclidean distance as the similarity model
is unrealistic, since its performance degrades rapidly in the
presence of noise and this measure is also sensitive to small
variations in the time axis. We concentrate on two similarity
models: the first is an extension of Dynamic Time
Warping for higher dimensions. We note that DTW has
been used so far for one-dimensional time series. Here we
present a formulation for sequences of arbitrary dimensions.
The second distance measure is a modification of the Longest
Common Subsequence (LCSS), specially adapted for continuous
values. Both measures represent a significant improvement
compared to the Euclidean distance. However, LCSS
is more robust than DTW under noisy conditions [20] as figure
1 shows. Euclidean matching completely disregards the
variations in the time axis, while DTW performs excessive
matchings, therefore distorting the true distance between sequences
. The LCSS produces the most robust and intuitive
correspondence between points.
By incorporating warping in time as a requirement to
216
0
20
40
60
80
100
120
Euclidean Matching
0
20
40
60
80
100
120
Time Warping
0
20
40
60
80
100
120
Longest Common Subsequence
Figure 1: A lucid example about the quality matching of the LCSS compared to other distance functions.
The Euclidean distance performs an inflexible matching, while the DTW gives many superfluous and spurious
matchings, in the presence of noise.
our model, our algorithms are automatically challenged with
quadratic execution time. Moreover, these flexible functions
are typically non-metric, which makes difficult the design of
indexing structures. To speed up the execution of a similarity
function, one can devise a low cost, upper bounding function
(since the LCSS model captures the similarity, which
is inversely analogous to the distance). We utilize a fast
prefiltering scheme that will return upper bound estimates
for the LCSS similarity between the query and the indexed
trajectories. In addition to providing similarity measures
that guarantee no false dismissals, we also propose approximate
similarity estimates that significantly reduce the index
response time. Finally, we show that the same index can
support other distance measures as well.
Our technique works by splitting the trajectories in multidimensional
MBRs and storing them in an R-tree. For a
given query, we construct a Minimum Bounding Envelope
(MBE) that covers all the possible matching areas of the
query under warping conditions. This MBE is decomposed
into MBRs and then probed in the R-tree index. Using the
index we can discover which trajectories could potentially
be similar to the query. The index size is compact and its
construction time scales well with the trajectory length and
the database size, therefore our method can be utilized for
massive datamining tasks.
The main contributions of the paper are:
We present the first external memory index for multidimensional
trajectories, that supports multiple distance
functions (such as LCSS, DTW and Euclidean), without the
need to rebuild the index.
We give efficient techniques for upper(lower) bounding
and for approximating the LCSS(DTW) for a set of trajectories
. We incorporate these techniques in the design of an
efficient indexing structure for the LCSS and the DTW.
We provide a flexible method that allows the user to
specify queries of variable warping length, and the technique
can be tuned to optimize the retrieval time or the accuracy
of the solution.
RELATED WORK
There has been a wealth of papers that use an L
p
distance
family function to perform similarity matching for
1D time-series. Work on multidimensional sequences can
be found in [14, 9]. However, they support only Euclidean
distance, which, as mentioned in the introduction, cannot
capture flexible similarities.
Although the vast majority of database/data mining research
on time series data mining has focused on Euclidean
distance, virtually all real world systems that use time series
matching as a subroutine, use a similarity measure which allows
warping. In retrospect, this is not very surprising, since
most real world processes, particularly biological processes,
can evolve at varying rates. For example, in bioinformat-ics
, it is well understood that functionally related genes will
express themselves in similar ways, but possibly at different
rates. Because of this, DTW is used for gene expression data
mining [1, 3]. Dynamic Time Warping is a ubiquitous tool
in the biometric/surveillance community. It has been used
for tracking time series extracted from video [7], classifying
handwritten text [16] and even fingerprint indexing [13].
While the above examples testify to the utility of a time
warped distance measure, they all echo the same complaint;
DTW has serious scalability issues. Work that attempted to
mitigate the large computational cost has appeared in [12]
and [21], where the authors use lower bounding measures to
speed up the execution of DTW. However, the lower bounds
can be loose approximations of the original distance, when
the data are normalized. In [15] a different approach is used
for indexing Time Warping, by using suffix trees. Nonetheless
, the index requires excessive disk space (about 10 times
the size of the original data).
The flexibility provided by DTW is very important, however
its efficiency deteriorates for noisy data, since by matching
all the points, it also matches the outliers distorting the
true distance between the sequences. An alternative approach
is the use of Longest Common Subsequence (LCSS),
which is a variation of the edit distance. The basic idea is
to match two sequences by allowing them to stretch, without
rearranging the order of the elements but allowing some
elements to be unmatched.
Using the LCSS of two sequences
, one can define the distance using the length of this
subsequence [6]. In [20] an internal memory index for the
LCSS has been proposed. It also demonstrated that while
the LCSS presents similar advantages to DTW, it does not
share its volatile performance in the presence of outliers.
Closest in spirit to our approach, is the work of [10] which,
however, only addresses 1D time-series. The author uses
constrained DTW as the distance function, and surrounds
the possible matching regions by a modified version of a
Piecewise Approximation, which is later stored as equi-length
MBRs in an R-tree.
However, by using DTW, such an
approach is susceptible to high bias of outliers. Also, the
217
fixed MBR size (although simplifies the index operations)
can lead to degenerate approximations of the original sequence
. Moreover, the embedding of the envelope in the
indexed sequences can slow the index construction time and
limit the user's query capabilities to a predefined warping
length. The use of LCSS as our primary similarity measure,
lends itself to a more natural use of the R-tree, where the
similarity estimates are simply computed by calculating the
MBR intersection areas. Since the index is not constructed
for a specific warping window, the user can pose queries with
variable warping length.
The purpose of this paper is to reconcile the best of both
worlds. We provide a framework that can support in the
same index, the LCSS, DTW and Euclidean distance functions
. The only aspect that changes, is the different representation
of the query for each distance measure.
DISTANCE MEASURES
In this section we present details of how the Dynamic
Time Warping and the LCSS model can be extended to describe
the similarity between trajectories.
3.1 Dynamic Time Warping for 2D trajectories
We describe an extension in 2D of the original DTW function
as described by Berndt and Clifford [4]. Let A and B
be two trajectories of moving objects with size n and m
respectively, where A = ((a
x,1
, a
y,1
), . . . , (a
x,n
, a
y,n
)) and
B = ((b
x,1
, b
y,1
), . . . , (b
x,m
, b
y,m
)). For a trajectory A, let
Head(A) = ((a
x,1
, a
y,1
), . . . , (a
x,n
­
1
, a
y,n
­
1
)).
Definition 1. The Time Warping between 2-dimensional
sequences A and B is:
DT W (A, B)
=
L
p
((a
x,n
, a
y,n
), (b
x,m
, b
y,m
)) +
min
{DTW(Head(A),
Head(B)), DT W (Head(A), B),
DT W (A, Head(B))
}
(1)
where L
p
is any p-Norm. Using dynamic programming and
constraining the matching region within , the time required
to compute DTW is O((n + m)). In order to represent an
accurate relationship of distances between sequences with
different lengths, the quantity in equation 1 is normalized
by the length of the warping path. The extension to n dimensions
is similar. In figure 2 we show an example of time
warping for two trajectories.
3.2 LCSS model for 2D trajectories
The original LCSS model refers to 1D sequences, we must
therefore extend it to the 2D case. In addition, the LCSS
paradigm matches discrete values, however in our model we
want to allow a matching, when the values are within a
certain range in space and time (note that like this, we also
avoid distant and degenerate matchings).
Definition 2. Given an integer  and a real number 0 &lt;
&lt; 1, we define the LCSS
,
(A, B) as follows:
LCSS
,
(A, B) =

0
if A or B is empty
1 + LCSS
,
(Head(A), Head(B))
if
|a
x,n
­ b
x,m
| &lt;
and
|a
y,n
­ b
y,m
| &lt;
and
|n ­ m|
max(LCSS
,
(Head(A), B),
LCSS
,
(A, Head(B))),
otherwise
0
50
100
150
0
500
1000
1500
100
200
300
400
500
600
X movement
Time
Y movement
Figure 2: The support of flexible matching in spatiotemporal
queries is very important. However, we
can observe that Dynamic Time Warping matches
all points (so the outliers as well), therefore distorting
the true distance. In contrast, the LCSS model
can efficiently ignore the noisy parts.
where sequences A and Head(A) are defined similarly as
before. The constant  controls the flexibility of matching
in time and constant
is the matching threshold is space.
The aforementioned LCSS model has the same O((n+m))
computational complexity as the DTW, when we only allow
a matching window  in time [6].
The value of LCSS is unbounded and depends on the
length of the compared sequences. We need to normalize
it, in order to support sequences of variable length. The
distance derived from the LCSS similarity can be defined as
follows:
Definition 3. The distance D
,
expressed in terms of
the LCSS similarity between two trajectories A and B is
given by:
D
,
(A, B) = 1 ­ LCSS
,
(A, B)
min(n, m)
(2)
INDEX CONSTRUCTION
Even though imposing a matching window  can help
speed up the execution, the computation can still be quadratic
when  is a significant portion of the sequence's length.
Therefore, comparing a query to all the trajectories becomes
intractable for large databases. We are seeking ways to avoid
examining the trajectories that are very distant to our query.
This can be accomplished by discovering a close match to
our query, as early as possible. A fast pre-filtering step is
employed that eliminates the majority of distant matches.
Only for some qualified sequences will we execute the costly
(but accurate) quadratic time algorithm. This philosophy
has also been successfully used in [21, 10]. There are certain
preprocessing steps that we follow:
1. The trajectories are segmented into MBRs, which are
stored in an Rtree T.
2. Given a query Q, we discover the areas of possible
matching by constructing its Minimum Bounding Envelope
(M BE
Q
).
3. M BE
Q
is decomposed into MBRs that are probed in
the index T.
218
4. Based on the MBR intersections, similarity estimates
are computed and the exact LCSS (or DTW) is performed
only on the qualified trajectories.
The above notions are illustrated in figure 3 and we explain
in detail how they can be applied for the LCSS case in the
sections that follow.
E. LCSS Upper Bound Estimate = L1+L2+L3
A. Query Q
C. Envelope Splitting
B. Query Envelope
D. Sequence MBRs
L1
L2
L3
Figure 3: An example of our approach (in 1D for
clarity); A query is extended into a bounding envelope
, which in turn is also split into the resulting
MBRs. Overlap between the query and the index
MBRs suggest areas of possible matching.
4.1 Bounding the Matching Regions
Let us first consider a 1D time-series and let a sequence
A be (a
x,1
, . . . , a
x,n
). Ignoring for now the parameter , we
would like to perform a very fast LCSS

match between
sequence A and some query Q. Suppore that we replicate
each point Q
i
for  time instances before and after time i.
The envelope that includes all these points defines the areas
of possible matching. Everything outside this envelope can
never be matched.
10
20
30
40
50
60
70
40 pts
6 pts
2


Q
A
Figure 4: The Minimum Bounding Envelope (MBE)
within  in time and
in space of a sequence. Everything
that lies outside this envelope can never be
matched.
We call this envelope, the Minimum Bounding Envelope
(MBE) of a sequence. Also, once we incorporate the matching
within
in space, this envelope should extent
above
and below the original envelope (figure 4). The notion of the
bounding envelope can be trivially extended in more dimensions
, where M BE(, ) for a 2D trajectory Q = ((q
x,1
, q
y,1
),
. . . , (q
x,n
, q
y,n
) covers the area between the following time-series
:
EnvLow
MBE(, )  EnvHigh, where:
EnvHigh[i] = max(Q[j] + epsilon)
,
|i­j|
EnvLow[j] = min(Q[j] ­ epsilon)
,
|i­j|
The LCSS similarity between the envelope of Q and a sequence
A is defined as:
LCSS(M BE
Q
, A) =
n
i=1
1
if A[i] within envelope
0
otherwise
For example, in figure 4 the LCSS similarity between M BE
Q
and sequence A is 46, as indicated in the figure. This value
represents an upper bound for the similarity of Q and A.
We can use the M BE
Q
to compute a lower bound on the
distance between trajectories:
Lemma 1. For any two trajectories Q and A the following
holds: D
,
(M BE
Q
, A)
D
,
(Q, A),
Proof (Sketch): D
,
(M BE
Q
, A) = 1 ­
LCSS
,
(M BE
Q
,A)
min(
|Q|,|A|)
,
therefore it is sufficient to show that: LCSS
,
(M BE
Q
, A)

LCSS
,
(Q, A). This is true since M BE
Q
by construction
contains all possible areas within  and
of the query Q.
Therefore, no possible matching points will be missed. 2
The previous lemma provides us with the power to create
an index that guarantees no false dismissals. However, this
lower bound refers to the raw data. In the sections that follow
, we will 'split' the M BE of a trajectory, into a number
of Minimum Bounding Rectangles (MBRs), to accommodate
their storage into a multidimensional R-tree. We will
show that the above inequality still holds between trajectory
MBRs.
The MBR generation procedure is orthogonal to our approach
, since any segmentation methodology can be applied
to our framework. Therefore, the description of the potential
MBR generation methods (and of our implementation
choice) will be delayed until later.
QUICK PRUNING OF DISSIMILAR TRA-JECTORIES
Suppose that we have an index with the segmented trajectories
and the user provides a query Q. Our goal is the
discovery of the k closest trajectories to the given query, according
to the LCSS similarity. A prefiltering step will aid
the quick discovery of a close match to the query, helping
us discard the distant trajectories without using the costly
quadratic algorithm. Therefore, in this phase, we compute
upper bound estimates of the similarity between the query
and the indexed sequences using their MBRs.
Below we describe the algorithm to find the closest trajectory
to a given query:
Input: Query Q, Index I with trajectory MBRs, Method
Output: Most similar trajectory to Q.
219
Box Env = constructM BE
,
(Q);
Vector V
Q
= CreateM BRs(Env);
// V
Q
contains a number of boxes.
Priority queue P Q
;
// P Q keeps one entry per trajectory sorted
// according to the similarity estimate
for each box B in V
Q
:
V = I.intersectionQuery(B);
// V contains all trajectory MBRs that intersect with B.
if Method == Exact: // upper bound
P Q
computeL-SimilarityEstimates(V, B);
else: // approximate
P Q
computeV-SimilarityEstimates(V, B);
BestSoF ar = 0; Best
;
while P Q not empty:
E
PQ.top;
if E.estimate &lt; BestSoF ar: break;
else:
D = computeLCCS
,
(Q, E); // exact
if D &gt; BestSoF ar:
BestSoF ar = D; Best
E;
Report Best;
The above algorithm can be adjusted to return the kNN
sequences, simply by comparing with the k
th
bestSoF ar
match. Next, we examine the possible similarity estimates.
Some of them guarantee that will find the best match (they
lower bound the original distance or upper bound the original
similarity), while other estimates provide faster but approximate
results.
5.1 Similarity Estimates
Here we will show how to compute estimates of the LCSS
similarity, based on the geometric properties of the trajectory
MBRs and their intersection. An upper bound estimate
is provided by the length of the MBR intersection and an
approximate estimate is given as a parameter of the intersecting
volume. To formalize these notions, first we present
several operators. Then we will use these operators to derive
the estimates.
5.1.1 Estimates for the LCSS
Each trajectory T can be decomposed into a number of
MBRs. The i
th
3D MBR of T consists of six numbers:
M
T,i
=
{t
l
, t
h
, x
l
, x
h
, y
l
, y
h
}. Now, let us define the operators
(c)
t
,
(p)
t
and
V
between two 3D MBRs M
P,i
and
M
R,j
, belonging to objects P and R, respectively:
1.
(c)
t
(M
P,i
, M
R,j
) =
||Intersection||
t
,
where M
R,j
.x
l
M
P,i
.x
l
M
R,j
.x
h
and
M
R,j
.x
l
M
P,i
.x
h
M
R,j
.x
h
and
M
R,j
.y
l
M
P,i
.y
l
M
R,j
.y
h
and
M
R,j
.y
l
M
P,i
.y
h
M
R,j
.y
h
or similarly by rotating M
R,j
M
P,i
Therefore, this operator computes the time intersection
of two MBR when one fully contains the other in
the x,y dimensions.
2.
(p)
t
(M
P,i
, M
R,j
) =
||Intersection||
t
, otherwise
3.
V
(M
P,i
, M
R,j
) =
||Intersection||
t
||Intersection||
x

||Intersection||
y
We can use upper bound or approximate estimates for the
similarity:
Common Volume Intersection
The Intersection of MBRs is fully 
contained within one MBR
Intersection between two MBRs
time
y
x
Figure 5:
Top left:
Intersection recorded in list
L
t,partial
.
Top right: Intersection recorded in list
L
t,complete
. Bottom left: Percentage of Volume Intersection
kept in L
V
.
1. Upper bound estimates (L-similarity estimate).
Such estimates are computed using the following data-structures:
The list L
t,complete
, an element L(P ) of which is defined
as:
L(P ) =
m
n
M
Q,m
(c)
t
M
P,n
where Q is a query and P is a trajectory in the index. So the
list stores for each trajectory the total time that its MBRs
intersected with the query's MBRs. We record into this list
only the intersections, where a query MBR is fully contained
in all spatial dimensions by a trajectory MBR (or vice versa
-it is equivalent. See figure 5, top right).
The list L
t,partial
, an element L(P ) of which is defined as:
L(P ) =
m
n
M
Q,m
(p)
t
M
P,n
This list records for each sequence the total intersection
in time for those query MBRs that are not fully contained
within the x,y dimensions by the trajectory MBRs (or vice
versa. Figure 5, top left).
Regarding a query Q, for any trajectory P the sum of
L
t,complete
(P ) + L
t,partial
(P ) will provide an upper bound
on the similarity of P and Q.
The reason for the distinction of the L-similarity estimate
in two separate lists derives from the fact that the estimates
stored in list L
t,partial
can significantly overestimate
the LCSS similarity. If one wishes to relax the accuracy,
in favor of enhanced performance, it is instructive to give a
weight 0 &lt; w
p
&lt; 1 to all estimates in list L
t,partial
. Even
though now we may miss the best match to our query, we
are going to find a close match in less time. This weighted
approach is used when we are seeking for approximate, but
very good quality answers, however it will not be explained
further due to space limitations.
2. Approximate estimates (V-similarity estimate).
This second estimate is based on the intersecting volume of
the MBRs. This type of estimates are stored in list L
V
:
Any element L
V
(P ) of list L
V
records similarity estimates
between trajectory P and query Q, based on the total volume
intersection between the MBRs of P and Q.
L(P ) =
1
length(P )
m
n
M
Q,m
V
M
P,n
||M
Q,m
||
V
||M
Q,m
||
t
220
where
||M||
V
denotes the volume of MBR M and
||M||
t
its
length on the time axis.
The L-similarity overestimates the LCSS
,
between two
sequences A and B and so it can be deployed for the design
of an index structure.
Lemma 2. The use of the L-similarity estimate upper bounds
the LCSS
,
similarity between two sequences A and B and
therefore does not introduce any false dismissals.
The V-similarity estimate can be used for approximate
query answering. Even though it does not guarantee the
absence of false dismissals, the results will be close to the
optimal ones with high probability. Also, because this estimate
provides a tighter approximation to the original distance
, we expect faster response time. Indeed, as we show in
the experimental section, the index performance is boosted,
while the error in similarity is frequently less then 5%.
5.2 Estimates for the DTW
When the distance function used is the Time Warping,
using the index we obtain a lower bound of the actual distance
. In this case we have the inverse situation from the
LCSS; instead of calculating the degree of overlap between
the MBRs of the indexed trajectories and the query, we evaluate
the distance between the MBRs. The overall distance
between the MBRs underestimates the true distance of the
trajectories, and no false dismissals are introduced. Using
the MBRs we can also calculate upper bound estimates on
the distance, which hadn't been exploited in previous work
[10, 22]. Sequences with lower bound larger than the smallest
upper bound can be pruned. With this additional prefiltering
step we can gain on average an additional 10-15%
speedup in the total execution time.
Due to space limitations only a visual representation of
this approach is provided in figure 6.
MBR GENERATION
Given a multidimensional time-series (or an MBE) our
objective is to minimize the volume of the sequence using
k MBRs. Clearly, the best approximation of a trajectory
(or an MBE) using a fixed number of MBRs is the set of
MBRs that completely contain the sequence and minimize
the volume consumption. We can show the following lemma:
Lemma 3. Minimizing the volume of the Minimum Bounding
Envelope, minimizes the expected similarity approximation
error.
Three different approaches are considered:
1. k-Optimal. We can discover the k MBRs of a sequence
that take up the least volume, using a dynamic programming
algorithm that requires O(n
2
k) time ([8]), where n is the
length of the given sequence. Since this approach is not
reasonable for large databases, we are motivated to consider
approximate and faster solutions.
2. Equi-Split. This technique produces MBRs of fixed
length l. It is a simple approach with cost linear in the
length of a sequence. However, in pathological cases increasing
the number of splits can result to larger space utilization
,therefore the choice of the MBR length becomes a
critical parameter (see figure 7 for an example).
A. Query Q
B. Query Envelope
C. Envelope Splitting
D. Sequence MBRs
E. MINDIST(Q,R)
F. MAXDIST(Q,R)
Figure 6: A visual intuition of the DTW indexing
technique (the one-dimensional case is shown for
clarity).
The original query (A) is enclosed in a
minimum-bounding envelope (B) like the LCSS approach
. The MBE is split into its MBRs using equi
or greedy split (fig. (C)). The candidate sequences
in the database have their MBRs stored in the index
(D). Between the query and any sequence in
the index, the minimum and maximum distance can
be quickly determined by examining the distance
between the MBRs and the query's bounding envelope
, as represented by the arrows in (E) and (F).
3. Greedy-Split. The Greedy approach is our implementation
choice in this paper. Initially we assign an MBR to
each of the n sequence points and at each subsequent step
we merge the consecutive MBRs that will introduce the least
volume consumption. The algorithm has a running time of
O(nlogn). We can see a sketch of the method in fig. 8. Al-ternatively
, instead of assigning the same number of splits
to all objects, according to our space requirements we can
assign a total of K splits to be distributed among all objects.
This method can provide better results, since we can assign
more splits for the objects that will yield more space gain.
Also, this approach is more appropriate when one is dealing
with sequences of different lengths. The complexity of this
approach is O(K + N logN ), for a total of N objects ([8]).
Input: A spatiotemporal trajectory T and an integer k denoting
the number of final MBRs.
For 0
i &lt; n compute the volume of the MBR produced by
merging T
i
and T
i+1
. The results are stored in a priority queue.
While #M BRs &lt; k: Using the priority queue, merge the pair
of consecutive MBRs that yield the smallest increase in volume.
Delete the two merged MBRs and insert the new one in the priority
queue.
Output: A set of MBRs that cover T .
Figure 8: The greedy algorithm for producing k
MBRs that cover the trajectory T .
After a trajectory is segmented the MBRs can be stored
in a 3D-Rtree. Using the greedy split each additional split
will always lead to smaller (or equal) volume (figure 7). A
similar greedy split algorithm is also used for splitting the
MBE of the query trajectory Q.
221
(a)
Equi-Split, 8 MBRs, Gain = 5.992
(b)
Equi-Split, 9 MBRs, Gain = 5.004
(c)
Greedy-Split, 8MBRs, Gain = 9.157
(d)
Greedy-Split, 9MBRs, Gain = 10.595
Figure 7: (a): 8 MBRs produced using equi-Split. The volume gain over having 1 MBR is 5.992. (b):
Segmenting into 9 MBRs decreases the volume gain to 5.004. So, disk space is wasted without providing
a better approximation of the trajectory. (c): 8 MBRs using greedy-Split. The volume gain over having 1
MBR is 9.157. (d): Every additional split will yield better space utilization. Segmentation into 9 MBRs
increases volume gain to 10.595.
SUPPORTING MULTIPLE MEASURES
The application of the Minimum Bounding Envelope only
on the query suggests that user queries are not confined to
a predefined and rigid matching window . The user can
pose queries of variable warping in time. In some datasets,
there is no need to perform warping, since the Euclidean
distance performs acceptably [11]. In other datasets, by
using the Euclidean distance we can find quickly some very
close matches, while using warping we can distinguish more
flexible similarities. So, we can start by using a query with
 = 0 (no bounding envelope), and increase it progressively
in order to find more flexible matches (figure 9).
Therefore, our framework offers the unique advantage that
multiple distance functions can be supported in a single index
. The index sequences have been segmented without any
envelope applied on them and never have to be adjusted
again. For different measures, the aspects that change are,
the creation of the query envelope and the type of operation
between MBRs. In order to pose queries based on Euclidean
distance we follow the steps:
The query is segmented with no envelope applied on it.
The minDist and maxDist estimators for the Euclidean
distance are derived by calculating the distance between the
query and index MBRs, just like in the DTW case.
0
50
100
150
200
250
300
350
200
150
100
50
0
50
100
Index Trajectory
Query
Figure 9: By incorporating the bounding envelope
on the query, our approach can support Euclidean
distance, constrained or full warping. This is accomplished
by progressively expanding the MBE.
EXPERIMENTAL EVALUATION
In this section we compare the effectiveness of various
splitting methods and we demonstrate the superiority of our
lower bounding technique (for the DTW) compared to other
proposed lower bounds. We describe the datasets we used
and present comprehensive experiments regarding the index
performance for the two similarity estimates. In addition,
we evaluate the accuracy of the approximate estimates. All
experiments conducted were run on an AMD Athlon 1.4 Ghz
with 1GB RAM and 60GB of hard drive.
1. ASL
2. Buoy Sensor
3. Video Track 1
4. Flutter
5. Marine Mammals
6. Word Tracking
7. Random Walk
8. Video Track 2
Figure 10: Datasets used for testing the efficiency
of various MBR generation methods.
8.1 MBR Generation Comparison
The purpose of our first experiment is to test the s