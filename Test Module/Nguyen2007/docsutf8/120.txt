KDDCS: A Load-Balanced In-Network Data-Centric Storage Scheme for Sensor Networks
ABSTRACT
We propose an In-Network Data-Centric Storage (INDCS) scheme
for answering ad-hoc queries in sensor networks. Previously proposed
In-Network Storage (INS) schemes suffered from Storage
Hot-Spots that are formed if either the sensors' locations are not
uniformly distributed over the coverage area, or the distribution
of sensor readings is not uniform over the range of possible reading
values. Our K-D tree based Data-Centric Storage (KDDCS)
scheme maintains the invariant that the storage of events is distributed
reasonably uniformly among the sensors. KDDCS is composed
of a set of distributed algorithms whose running time is
within a poly-log factor of the diameter of the network. The number
of messages any sensor has to send, as well as the bits in those
messages, is poly-logarithmic in the number of sensors. Load balancing
in KDDCS is based on defining and distributively solving
a theoretical problem that we call the Weighted Split Median problem
. In addition to analytical bounds on KDDCS individual algorithms
, we provide experimental evidence of our scheme's general
efficiency, as well as its ability to avoid the formation of storage
hot-spots of various sizes, unlike all previous INDCS schemes.
Categories and Subject Descriptors
H.2.4 [Database Management]: Systems--Distributed
databases, Query processing

General Terms
Algorithms, Design, Experimentation, Performance

INTRODUCTION
Sensor networks provide us with the means of effectively monitoring
and interacting with the physical world. As an illustrative
example of the type of sensor network application that concerns
us here, consider an emergency/disaster scenario where sensors are
This work has been funded in part by NSF grants ANI-0325353,
CCF-0448196, CCF-0514058, and IIS-0534531.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
CIKM'06, November 5Â­11, 2006, Arlington, Virginia, USA.
Copyright 2006 ACM 1-59593-433-2/06/0011 ...
$
5.00.
deployed in the area of the disaster [17]. It is the responsibility of
the sensor network to sense and store events of potential interest.
An event is composed of one or more attributes (e.g. temperature,
carbon monoxide level, etc.), the identity of the sensor that sensed
the event, and the time when the event was sensed. As first responders
move through the disaster area with hand-held devices, they
issue queries about recent events in the network. For example, the
first responder might ask for the location of all sensor nodes that
recorded high carbon monoxide levels in the last 15 minutes, or
he might ask whether any sensor node detected movement in the
last minute. Queries are picked up by sensors in the region of the
first responder. The sensor network is then responsible for answering
these queries. The first responders use these query answers to
make decisions on how to best manage the emergency.
The ad-hoc queries of the first responders will generally be multi-dimensional
range queries [9], that is, the queries concern sensor
readings that were sensed over a small time window in the near past
and that fall in a given range of the attribute values. In-Network
Storage (INS) is a storage technique that has been specifically presented
to efficiently process this type of queries. INS involves storing
events locally in the sensor nodes. Storage may be in-network
because it is more efficient than shipping all the data (i.e., raw sensor
readings) out of the network (for example to base stations), or
simply because no out-of-network storage is available. All INS
schemes already presented in literature were Data-Centric Storage
(DCS) schemes [15]. In any In-Network Data-Centric Storage (INDCS
) scheme, there exists a function from events to sensors that
maps each event to an owner sensor based on the value of the attributes
of that event. The owner sensor will be responsible for
storing this event. The owner may be different than the sensor that
originally generated the event. To date, the Distributed Index for
Multi-dimensional data (DIM) scheme [9] has been shown to exhibit
the best performance among all proposed INDCS schemes in
dealing with sensor networks whose query loads are basically composed
of ad-hoc queries .
In DIM [9], the events-to-sensors mapping is based on a K-D tree
[3], where the leaves
R form a partition of the coverage area, and
each element of
R contains either zero or one sensor. The formation
of the K-D tree consists of rounds. Initially,
R is a one element
set containing the whole coverage area. In each odd/even round r,
each region R  R that contains more than one sensor is bisected
horizontally/vertically. Each time that a region is split, each sensor
in that region has a bit appended to its address specifying which
side of the split the sensor was on. Thus, the length of a sensor's
address (bit-code) is its depth in the underlying K-D tree. When a
sensor generates an event, it maps such event to a binary code based
on a repetitive fixed uniform splitting of the attributes' ranges in a
round robin fashion. For our purposes, it is sufficient for now to
317
consider the cases that the event consists of only one attribute, say
temperature. Then, the high order bits of the temperature are used
to determine a root-to-leaf path in the K-D tree, and if there is a
sensor in the region of the leaf, then this sensor is the owner of this
event. Due to the regularity of regions in this K-D tree, the routing
of an event from the generating sensor to the owner sensor is particularly
easy using Greedy Perimeter Stateless Routing (GPSR) [6].
Full description of DIM is presented in Section 2.
Though it is the best DCS scheme so far, DIM suffers from several
problems. One problem is that events may well be mapped to
orphan regions that contain no sensors. Thus, DIM requires some
kludge to assign orphan regions to neighboring sensors.
Another major problem in DIM is that of storage hot-spots. Storage
hot-spots may occur if the sensors are not uniformly distributed.
A storage hot-spot occurs when relatively many events are assigned
to a relatively small number of the sensors. For example, if there
was only one sensor on one side of the first bisection, then half of
the events would be mapped to this sensor if the events were uniformly
distributed over the range of possible events. Due to their
storage constraints, the presence of a storage hot-spot leads to increasing
the dropping rate of events by overloaded sensors. Clearly,
this has a significant impact on the quality of data (QoD) generated
by the sensor network. Queries for events in a storage hot-spot may
be delayed due to contention at the storage sensors and the surrounding
sensors. More critically, the sensors in and near the hot-spot
may quickly run out of energy, due to the high insertion/query
load imposed to them. This results in a loss of the events generated
at these sensors, the events stored at these sensors, and possibly a
decrease in network connectivity. Increased death of sensors results
in decreasing the coverage area and causes the formation of coverage
gaps within such area. Both of which consequently decrease
QoD. Certainly, it is not desirable to have a storage scheme whose
performance and QoD guarantees rest on the assumption that the
sensors are uniformly distributed geographically.
Storage hot-spots may also occur in DIM if the distribution of
events is not uniform over the range of possible events. It is difficult
to imagine any reasonable scenario where the events are uniformly
distributed over the range of all possible events. Consider the situation
where the only attribute sensed is temperature. One would
expect that most temperature readings would be clustered within a
relatively small range rather than uniform over all possible temperatures
. Without any load balancing, those sensors responsible for
temperatures outside this range would store no events.
In this paper, we provide a load-balanced INDCS scheme based
on K-D trees, that we, not surprisingly, call K-D tree based DCS
(KDDCS). In our KDDCS scheme, the refinement of regions in the
formation of the K-D tree has the property that the numbers of sensors
on both sides of the partition are approximately equal. As a
result of this, our K-D tree will be balanced, there will be no orphan
regions, and, regardless of the geographic distribution of the
sensors, the ownership of events will uniformly distributed over
the sensors if the events are uniformly distributed over the range
of possible events. We present a modification of GPSR routing,
namely Logical Stateless Routing (LSR), for the routing of events
from their generating sensors to their owner sensors, that is competitive
with the GPSR routing used in DIM. In order to maintain
load balance in the likely situation that the events are not uniformly
distributed, we present a re-balancing algorithm that we call K-D
Tree Re-balancing (KDTR). Our re-balancing algorithm guarantees
load balance even if the event distribution is not uniform. KDTR
has essentially minimal overhead. We identify a problem, that we
call the weighted split median problem, that is at the heart of both
the construction of the initial K-D tree, and the re-balancing of the
K-D tree. In the weighted split median problem, each sensor has an
associated weight/multiplicity, and the sensors' goal is to distributively
determine a vertical line with the property that the aggregate
weight on each side of the line is approximately equal. We give a
distributed algorithm for the weighted split median problem, and
show how to use this algorithm to construct our initial K-D tree,
and to re-balance the tree throughout the network lifetime.
We are mindful of the time, message complexity, and node storage
requirements, in the design and implementation of all of our
algorithms. The time for all of our algorithms is within a poly-log
factor of the diameter of the network. Obviously, no algorithm can
have time complexity less than the diameter of the network. The
number of messages, and number of bits in those messages, that
any particular node is required to send by our algorithms is poly-logarithmic
in number of sensors. The amount of information that
each node must store to implement one of our algorithms is logarithmic
in the number of sensors.
Experimental evaluation shows that the main advantages of KDDCS
, when compared to the pure DIM, are:
Â· Achieving a better data persistence by balancing the storage
responsibility among sensor nodes.
Â· Increasing the QoD by distributing the storage hot-spot events
among a larger number of sensors.
Â· Increasing the energy savings by achieving a well balanced
energy consumption overhead among sensor nodes.
The rest of the paper is organized as follows. Section 2 presents
an overview of the differences between DIM and KDDCS. Section
3 describes the weighted split median problem, and our distributed
solution. Section 4 describes the components of KDDCS. Section 5
presents our K-D tree re-balancing algorithm. Experimental results
are discussed in Section 6. Section 7 presents the related work.
OVERVIEW OF DIM VS KDDCS
In this section, we will briefly describe the components of both
schemes, DIM and KDDCS, and highlight the differences between
the two schemes using a simple example.
We assume that the sensors are arbitrarily deployed in the convex
bounded region R. We assume also that each sensor is able to
determine its geographic location (i.e., its x and y coordinates), as
well as, the boundaries of the service area R. Each node is assumed
to have a unique NodeID, like a MAC address. Sensor nodes are
assumed to have the capacity for wireless communication, basic
processing and storage, and they are associated with the standard
energy limitations.
The main components of any DCS scheme are: the sensor to
address mapping that gives a logical address to each sensor, and
the event to owner-sensor mapping that determines which sensor
will store the event. The components of DIM and KDDCS are:
Â· Repetitive splitting of the geographic region to form the underlying
K-D tree, and the logical sensor addresses.
Â· Repetitive splitting of the attribute ranges to form the bit-code
for an event.
Â· The routing scheme to route an event from the generating
sensor to the owner sensor.
We now explain how DIM implements these components.
Let us start with the formation of the K-D tree in DIM. DIM
starts the network operation with a static node to bit-code mapping
phase. In such phase, each sensor locally determines its binary
address by uniformly splitting the overall service area in a round
318
Figure 1: Initial network configuration
Figure 2: DIM K-D tree
robin fashion, horizontally then vertically, and left shifting its bit-code
with every split by 0 (or 1) bit when falling above (or below)
the horizontal split line (similarly, by a 0 bit if falling on the left
of the vertical split line, or a 1 bit otherwise). Considering the
region as partitioned into zones, the process ends when every sensor
lies by itself in a zone, such that the sensor address is the zone bit
code. Thus, the length of the binary address of each sensor (in bits)
represents its depth in the underlying K-D tree. Note that from
a sensor address, one can determine the physical location of the
sensor. In case any orphan zones exist (zones physically containing
no sensors in their geographic area), the ownership of each of these
zones is delegated to one of its neighbor sensors. As an example,
consider the simple input shown in Figure 1. The K-D tree formed
by DIM is shown in Figure 2. In this figure, the orphan zone (01)
is assumed to be delegated to node 001, which is the least loaded
among its neighbors.
We now turn to the construction of an event bit-code in DIM.
The generation of the event bit-code proceeds in rounds. As we
proceed, there is a range R
j
associated with each attribute j of the
event. Initially, the range R
j
is the full range of possible values for
attribute j. We now describe how a round i  0 works. Round i,
determines the (i+1)
th
high order bit in the code. Round i depends
on attribute j = i mod k of the event, where k is the number of
attributes in the event. Assume the current value of R
j
is [a, c], and
let b = (a + c)/2 be the midpoint of the range R
j
. If the value of
attribute j is in the lower half of the range R
j
, that is in [a, b], then
the i
th
bit is 0, and R
j
is set to be the lower half of R
j
. If the value
of attribute j is in the upper half of the range R
j
, that is in [b, c],
then the i
th
bit is 1, and R
j
is set to be the upper half of R
j
.
To show the events to bit-code mapping in DIM, consider that
the events in our example (shown in Figure 2) are composed of
two attributes, temperature and pressure, with ranges (30, 70) and
(0, 2), respectively. Let an event with values (55, 0.6) be generated
by Node N3(11). The 4 high-order bits of the bit-code for this
event are 1001. This is because temperature is in the top half of
the range [30, 70], pressure is in the bottom half of the range [0, 2],
then temperature is in the bottom half of the range [50, 70], and
pressure is in the top half of the range [0, 1]. Thus, the event should
be routed toward the geometric location specified by code 1001.
In DIM, an event is routed using Greedy Perimeter Stateless
Routing (GPSR) [6] to the geographic zone with an address matching
the high order bits of the event bit-code. In our example, the
sensor 10 will store this event since this is the sensor that matches
Figure 3: KDDCS K-D tree
the high order bits of the bit-code 1001. If there is no sensor in this
region, then, the event is stored in a neighboring region.
We now highlight the differences between our proposed KDDCS
scheme, and DIM. The first difference is how the splitting is accomplished
during the formation of the K-D tree. In KDDCS, the split
line is chosen so that there are equal numbers of sensors on each
side of the split line. Recall that, in DIM, the split line was the geometric
bisector of the region. Thus, in KDDCS, the address of a
sensor is a logical address and does not directly specify the location
of the sensor. Also, note that the K-D tree in KDDCS will be balanced
, while this will not be the case in DIM if the sensors are not
uniformly distributed. This difference is illustrated by the K-D tree
formed by KDDCS shown in Figure 3 for the same simple input
shown in Figure 1. The second difference is that in determining the
owner sensor for an event, the range split point b need not be the
midpoint of the range R
j
. The value of b is selected to balance the
number of events in the ranges [a, b] and [b, c]. Thus, in KDDCS,
the storage of events will be roughly uniform over the sensors. The
third difference is that, since addresses are not geographic, KDDCS
needs a routing scheme that is more sophisticated than GPSR.
THE WEIGHTED SPLIT MEDIAN PROBLEM
Before presenting our KDDCS scheme, we first define the weighted
split median problem in the context of sensor networks and present
an efficient distributed algorithm to solve the problem. Each sensor
s
i
initially knows w
i
associated values v
1
, . . . v
w
i
. Let W =
P
n
i=1
w
i
be the number of values. The goal for the sensors is to
come to agreement on a split value V with the property that approximately
half of the values are larger than V and half of the values
are smaller than V .
We present a distributed algorithm to solve this problem. The
time complexity of our algorithm is O(log n) times the diameter of
the communication network in general, and O(1) times the diameter
if n is known a priori within a constant factor. Each node is
required to send only O(log n) sensor ID's. The top level steps of
this algorithm are:
1. Elect a leader sensor s , and form a breadth first search (BFS)
tree T of the communication network that is rooted at s .
2. The number of sensors n, and the aggregate number of values
W is reported to s .
3. The leader s collects a logarithmically-sized uniform random
sample L of the values. The expected number of times
that a value from sensor s
i
is included in this sample is

"
w
i
log n
W
"
.
4. The value of V is then the median of the reported values in
L, which s reports to all of the sensors.
We need to explain how these steps are accomplished, and why the
algorithm is correct.
319
We start with the first step. We assume that each sensor has a
lower bound k on the number of sensors in R. If a sensor has no
idea of the number of other sensors, it may take k = 2.
Then, each sensor decides independently, with probability  `
ln k
k
Â´,
to become a candidate for the leader. Each candidate sensor s
c
initiates
the construction of a BFS tree of the communication graph
rooted at s
c
by sending a message Construct(s
c
)
to its neighbors.
Assume a sensor s
i
gets a message Construct(s
c
) from sensor s
j
.
If this is the first Construct(s
c
) message that it has received, and
s
c
's ID is larger than the ID of any previous candidates in prior
Construct messages, then:
Â· s
i
makes s
j
its tentative parent in the BFS tree T , and
Â· forwards the Construct(s
c
) message to its neighbors.
If the number of candidates was positive, then, after time proportional
to the diameter of the communication network, there will
be a BFS tree T rooted at the candidate with the largest ID. Each
sensor may estimate an upper bound for the diameter of the communication
graph to be the diameter of R divided by the broadcast
radius of a sensor. After this time, the sensors know that they have
reached an agreement on T , or that there were no candidates. If
there were no candidates, each sensor can double its estimate of
k, and repeat this process. After O(log n) rounds, it will be the
case that k = (n). Once k = (n), then, with high probability
(that is, with probability 1
1
poly(n)
), the number of candidates
is (log n). Thus, the expected time complexity to accomplish
the first step is O(n log n). Assuming that each ID has O(log n)
bits, the expected number of bits that each sensors has to send is
O(log
2
n) since there are are likely only O(log n) candidates on
the first and only round in which there is a candidate. A log n factor
can be removed if each sensor initially knows an estimate of n
that is accurate to within a multiplicative constant factor.
The rest of the steps will be accomplished by waves of root-to-leaves
and leaves-to-root messages in T . The second step is easily
accomplished by a leave-to-root wave of messages reporting on the
number of sensors and number of values in each subtree. Let T
i
be
the subtree of T rooted at sensor s
i
, and W
i
the aggregate number
of values in T
i
. The value W
i
that s
i
reports to its parents is w
i
plus the aggregate values reported to s
i
by its children in T . The
sensor count that s
i
reports to its parents is one plus the sensor
counts reported to s
i
by its children in T .
The third step is also accomplished by a root-to-leaves wave and
then a leaves-to-root wave of messages. Assume a sensor s
i
wants
to generate a uniform random sample of L
i
of the values stored
in the sensors in T
i
. The value of L for the leader is (log n).
Let s
i
1
, . . . , s
i
d
be the children of s
i
in T . Node s
i
generates the
results to L
i
Bernoulli trials, where each trial has d + 1 outcomes
corresponding to s
i
and its d children. The probability that the
outcome of a trial is s
i
is
w
i
W
i
, and the probability that the outcome
is the child s
i
j
is
w
ij
W
i
. Then, s
i
informs each child s
i
j
how often it
was selected, which becomes the value of L
i
j
Â·s
i
, then waits until it
receives samples back from all of its children. s
i
then unions these
samples, plus a sample of values of the desired size from itself, and
then passes that sample back to its parent. Thus, each sensor has to
send O(log n) ID's.
The leader s then sets V to be the median of the values of the
sample L, then, in a root-to-leaves message wave, informs the other
sensors of the value of V .
We now argue that, with high probability, the computed median
of the values is close to the true median. Consider a value ^
V such
that only a fraction  &lt;
1
2
of the values are less than ^
V . One
can think of each sampled value as being a Bernoulli trial with outcomes
less and more depending on whether the sampled value is
Figure 4: Logical address assignment algorithm
less than ^
V . The number of less outcomes is binomially distributed
with mean L. In order for the computed median to be less than
^
V , one needs the number of less outcomes to be at least L/2, or
equivalently (
1
2
-)L more than the mean L. But the probability
that a binomially distributed variable exceeds its mean  by a factor
of 1 +  is at most e
-2
3
. Thus, by picking the multiplicative constant
in the sample size to be sufficiently large (as a function of ),
one can guarantee that, with high probability, the number of values
less than the computed median V cannot be much more than L/2.
A similar argument shows that the number more than the computed
median V can not be much more than L/2.
If the leader finds that n is small in step 2, it may simply ask all
sensors to report on their identities and locations, and then compute
V directly.
Now that we solved the weighted split median problem, we present
the components of the KDDCS scheme in the next section.
KDDCS
We now present our KDDCS scheme in details. We explain how
the initial K-D tree is constructed, how events are mapped to sensors
, and how events are routed to their owner sensors.
4.1
Distributed Logical Address Assignment
Algorithm
The main idea of the algorithm is that the split lines used to construct
the K-D tree are selected so that each of the two resulting
regions contain an equal number of sensors. The split line can be
determined using our weighted split median algorithm with each
sensor having unit weight, and the value for each sensor is either
its x coordinate or its y coordinate. The recursive steps of the algorithm
are shown in Figure 4. We now describe in some greater
detail how a recursive step works.
The algorithm starts by partitioning the complete region R horizontally
. Thus, the distributed weighted split median algorithm
(presented in section 3) is applied for R using the y-coordinates of
the sensors to be sent to the BFS root. Upon determining weighted
split median of R, sensors having lower y-coordinate than the median
value (we refer to these sensors as those falling in the lower
region of R) assign their logical address to 0. On the other hand,
those sensor falling on the upper region of R assign themselves a 1
logical address. At the end of the first recursive step, the terrain can
be looked at as split into two equally logically loaded partitions (in
terms of the number of sensors falling in each partition).
At the next step, the weighted split median algorithm is applied
locally in each of the sub-regions (lower/upper), while using the
sensors' x-coordinates, thus, partitioning the sub-regions vertically
rather than horizontally. Similarly, sensors' logical addresses are
updated by left-shifting them with a 0 bit for those sensors falling
320
in the lower regions (in other words, sensor nodes falling on the
left of the weighted median line), or with a 1 bit for sensor nodes
falling in the upper regions (i.e., sensor nodes falling on the right
of the weighted median line).
The algorithm continues to be applied distributively by the different
subtrees until each sensor obtains a unique logical address,
using x and y coordinates of sensors, in a round robin fashion, as
the criterion of the split. The algorithm is applied in parallel on
the different subtrees whose root nodes fall at the same tree level.
At the i
th
recursive step, the algorithm is applied at all intermediate
nodes falling at level i- 1 of the tree. Based on the definition of the
weighted split median problem, the algorithm results in forming a
balanced binary tree, such that sensors represent leaf nodes of this
tree (intermediate nodes of the tree are logical nodes, not physical
sensors). The algorithm terminates in log n recursive steps. At the
end of the algorithm, the size of the logical address given to each
sensor will be log n bits.
Recall that the time complexity of our weight split median algorithm
is O(d log n), where d is the diameter of the region. Thus,
as the depth of our K-D tree is O(log n), we get that the time complexity
for building the tree is O(d log
2
n). If the sensors are uniformly
distributed, then, as the construction algorithm recurses, the
diameters of the regions will be geometrically decreasing. Thus,
in the case of uniformly distributed sensors, one would expect the
tree construction to take time O(d log n). As our weighted split
median algorithm requires each sensor to send O(log n) ID's, and
our K-D tree has depth O(log n), we can conclude that during the
construction of our K-D tree, the number of ID's sent by any node
is O(log
2
n).
4.2
Event to Bit-code Mapping
In this section, we explain how the event to bit-code mapping
function is determined. Recall that the main idea is to set the split
points of the ranges so that the storage of events is roughly uniform
among sensor nodes. To construct this mapping requires a probability
distribution on the events. In some situations, this distribution
might be known. For example, if the network has been operational
for some period of time, a sampling of prior events might be used
to estimate a distribution. In cases where it is not known, say when
a network is first deployed, we can temporarily assume a uniform
distribution.
In both cases, we use the balanced binary tree as the base tree
to overlay the attribute-specific K-D tree on (Recall that a K-D tree
is formed by k attributes). This is basically done by assigning a
range for each of the k attributes to every intermediate node in the
tree. Note that the non-leaf nodes in the K-D tree are logical nodes
that do not correspond to any particular sensor. One may think of
non-leaf nodes as regions. Any split point p of a node x of tree
level l, where l%k = i, represents a value of attribute i. Such split
point partitions the range of attribute i falling under responsibility
of node x into two subranges such that the the subrange lower than
p is assigned to the left child of x, while the other range is assigned
to x's right child. Note that the other k - 1 ranges of node x,
corresponding to the remaining k-1 attributes, are simply inherited
by both children of x.
Knowing the data distribution, the split points of the tree should
be predefined in a way to cope with any expected irregularity in
the load distribution among the K-D tree leaf nodes. For example,
given an initial temperature range (30, 70) and knowing that 50%
of the events will fall in the temperature range (65, 70), the root
split point should be defined as 65 (assuming that the temperature
is the first attribute in the event). Therefore, based on the selected
root split point, the left child subtree of the root will be responsible
of storing events falling in the temperature range (30, 65),
while the right child subtree will store events falling in the range
(65, 70). Figure 3 gives an example of non-uniform initialization
of split points.
We finish by describing what information is stored in each sensor
node. Each sensor node corresponds to a leaf in the K-D tree. Each
sensor knows its logical address in the tree. Further, each leaf in
the K-D tree knows all the pertinent information about each of its
ancestors in the tree. The pertinent information about each node is:
Â· The geographic region covered.
Â· The split line separating its two children.
Â· The attribute range, and attribute split point, associated with
this region.
From this information, each leaf/sensor can determine the range of
events that will be stored at this sensor. Note that each sensor only
stores O(log n) information about the K-D tree.
4.3
Incremental Event Hashing and Routing
Strictly speaking, the events-to-sensors mapping in DIM actually
produces a geographic location. GPSR routing can then be used to
route that event towards that geographic location. If the destination
is contained in a leaf region with one sensor, then that sensor stores
the event. If the leaf region is an orphan, then one of the sensors in
the neighboring regions will store this event.
In our scheme, the events-to-sensors mapping provides a logical
address. Essentially, all that the sensor generating the event can
determine from this logical address is a general direction of the
owner sensor. Thus, our routing protocol, which we call Logical
Stateless Routing (LSR), is in some sense less direct.
LSR operates in O(log n) rounds. We explain how a round
works. Assume that a source sensor with a logical address s wants
to route an event e to a sensor with logical address t. However,
s does not know the identity of the sensor t. Recall that s knows
the pertinent information about its ancestors in the K-D tree. In
particular, s knows the range split values of its ancestors. Thus, s
can compute the least common ancestor (LCA) of s and t in the
K-D tree. Assume that the first bit of disagreement between s and
t is the
th
bit. So, the least common ancestor (LCA) of s and t
in the K-D tree has depth . Let R be the region corresponding to
the LCA of s and t, L the split line corresponding to this region,
and R
0
and R
1
the two subregions of R formed by L. Without
loss of generality, assume that s  R
0
and t  R
1
. From its own
address, and the address of t, the sensor s can conclude that t is in
the region R
1
. Recall that s knows the location of the split line L.
The sensor s computes a location x in the region R
1
. For concrete-ness
here, let us assume that x is some point in R
1
that lies on the
line intersecting s and perpendicular to L (Although there might be
some advantages to selecting x to be the geometric center of the region
R
1
). LSR then directs a message toward the location x using
GPSR. The message contains an additional field noting that this is
a
th
round message. The
th
round terminates when this message
first reaches a sensor s whose address agrees with the address of t
in the first + 1 bits. The sensor s will be the first sensor reached
i