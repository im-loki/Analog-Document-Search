Compression of Inverted Indexes For Fast Query Evaluation
ABSTRACT
Compression reduces both the size of indexes and the time
needed to evaluate queries. In this paper, we revisit the
compression of inverted lists of document postings that store
the position and frequency of indexed terms, considering two
approaches to improving retrieval efficiency:better implementation
and better choice of integer compression schemes.
First, we propose several simple optimisations to well-known
integer compression schemes, and show experimentally that
these lead to significant reductions in time. Second, we explore
the impact of choice of compression scheme on retrieval
efficiency.
In experiments on large collections of data, we show two
surprising results:use of simple byte-aligned codes halves
the query evaluation time compared to the most compact
Golomb-Rice bitwise compression schemes; and, even when
an index fits entirely in memory, byte-aligned codes result
in faster query evaluation than does an uncompressed index,
emphasising that the cost of transferring data from memory
to the CPU cache is less for an appropriately compressed index
than for an uncompressed index. Moreover, byte-aligned
schemes have only a modest space overhead:the most compact
schemes result in indexes that are around 10% of the
size of the collection, while a byte-aligned scheme is around
13%. We conclude that fast byte-aligned codes should be
used to store integers in inverted lists.
Categories and Subject Descriptors
H.3.4 [Information Storage and Retrieval]:Systems
and Software Performance evaluation (efficiency and effectiveness
); E.4 [Data]:Coding and Information Theory Data
compaction and compression
General Terms
Performance, Algorithms, Design
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGIR'02, August 11-15, 2002, Tampere, Finland.
Copyright 2002 ACM 1-58113-561-0/02/0008 ...
$
5.00.

INTRODUCTION
Search engines have demanding performance requirements.
Users expect fast answers to queries, many queries must be
processed per second, and the quantity of data that must
be searched in response to each query is staggering. The
demands continue to grow:the Google search engine, for
example, indexed around one billion documents a year ago
and now manages more than double that figure
1
. Moreover,
the increasing availability and affordability of large storage
devices suggests that the amount of data stored online will
continue to grow.
Inverted indexes are used to evaluate queries in all practical
search engines [14]. Compression of these indexes has
three major benefits for performance. First, a compressed
index requires less storage space. Second, compressed data
makes better use of the available communication bandwidth;
more information can be transfered per second than when
the data is uncompressed. For fast decompression schemes,
the total time cost of transfering compressed data and sub-sequently
decompressing is potentially much less than the
cost of transferring uncompressed data. Third, compression
increases the likelihood that the part of the index required
to evaluate a query is already cached in memory, thus entirely
avoiding a disk access. Thus index compression can
reduce costs in retrieval systems.
We have found that an uncompressed inverted index that
stores the location of the indexed words in web documents
typically consumes more than 30% of the space required
to store the uncompressed collection of documents. (Web
documents often include a great deal of information that is
not indexed, such as HTML tags; in the TREC web data,
which we use in our experiments, on average around half
of each document is indexable text.) When the index is
compressed, the index size is reduced to between 10%­15%
of that required to store the uncompressed collection; this
size includes document numbers, in-document frequencies,
and word positions within documents. If the index is too
large to fit entirely within main memory, then querying the
uncompressed index is slower:as we show later, it is up to
twice as slow as the fastest compressed scheme.
In this paper, we revisit compression schemes for the in-1
See http://www.google.com/
222
verted list component of inverted indexes. We also propose
a new method for decoding lists. There have been a great
many reports of experiments on compression of indexes with
bitwise compression schemes [6, 8, 12, 14, 15], which use an
integral number of bits to represent each integer, usually
with no restriction on the alignment of the integers to byte
or machine-word boundaries. We consider several aspects
of these schemes:how to decode bitwise representations of
integers efficiently; how to minimise the operations required
for the most compact scheme, Golomb coding; and the relative
performance of Elias gamma coding, Elias delta coding,
Golomb coding, and Rice coding for storing indexes.
We question whether bitwise compression schemes are the
best choice for storing lists of integers. As an alternative,
we consider bytewise integer compression schemes, which
require that each integer is stored in an integral number of
blocks, where each block is eight bits. The length of each
stored integer can therefore be measured in an exact number
of bytes. An additional restriction is to require that these
eight-bit blocks must align to machine-word or byte boundaries
.
We propose and experimentally investigate several
variations of bytewise schemes.
We investigate the performance of different index compression
schemes through experiments on large query sets
and collections of Web documents. We report two surprising
results.
· For a 20 gigabyte collection, where the index is several
times larger than main memory, optimised bytewise
schemes more than halve the average decoding time
compared to the fastest bitwise approach.
· For a much smaller collection, where the index fits in
main memory, a bytewise compressed index can still
be processed faster than an uncompressed index.
These results show that effective use of communication bandwidths
is important for not only disk-to-memory transfers
but also memory-to-cache transfers. The only disadvantage
of bytewise compressed indexes is that they are up to 30%
larger than bitwise compressed indexes; the smallest bitwise
index is around 10% of the uncompressed collection size,
while the bytewise index is around 13%.
INVERTED INDEXES
An inverted index consists of two major components:the
vocabulary of terms--for example the words--from the collection
, and inverted lists, which are vectors that contain
information about the occurrence of the terms [14].
In a basic implementation, for each term t there is an inverted
list that contains postings &lt; f
d,t
, d &gt; where f
d,t
is
the frequency f of term t in the ordinal document d. One
posting is stored in the list for each document that contains
the term t. Inverted lists of this form--along with additional
statistics such as the document length l
d
, and f
t
, the number
of documents that contain the term t--are sufficient to
support ranked and Boolean query modes.
To support phrase querying or proximity querying, additional
information must be kept in the inverted lists. Thus
inverted list postings should be of the form
&lt; f
d,t
, d, [o
0,d,t
. . . o
f
d,t
,d,t
] &gt;
The additional information is the list of offsets o; one offset
is stored for each of the f
d,t
occurrences of term t in
document d. Postings in inverted lists are usually ordered
by increasing d, and the offsets likewise ordered within the
postings by increasing o. This has the benefit that differences
between values--rather than the raw values--can be
stored, improving the compressibility of the lists.
Other arrangements of the postings in lists are useful when
lists are not necessarily completely processed in response to
a query. For example, in frequency-sorted indexes [9, 10]
postings are ordered by f
d,t
, and in impact-ordered indexes
the postings are ordered by quantised weights [1]. These approaches
also rely on compression to help achieve efficiency
gains, and the improvements to compression performance
we describe in this paper are as applicable to these methods
as they are to the simple index representations we use as a
testbed for our compression methods.
Consider an example inverted list with offsets for the term
"Matthew":
&lt; 3, 7, [6, 51, 117] &gt;&lt; 1, 44, [12] &gt;&lt; 2, 117, [14, 1077] &gt;
In this index, the terms are words, the offsets are word positions
within the documents, and the lists are ordered by d.
This inverted list states that the term "Matthew" occurs 3
times in document 7, at offsets 6, 51, and 117. It also occurs
once in document 44 at offset 12, and twice in document 117,
at offsets 14 and 1077.
Ranked queries can be answered using the inverted index
as follows. First, the terms in the user's query are located
in the inverted index vocabulary. Second, the corresponding
inverted lists for each term are retrieved from disk, and
then processed by decreasing f
t
. Third, for each posting in
each inverted list, an accumulator weight A
d
is increased;
the magnitude of the increase is dependent on the similarity
measure used, and can consider the weight w
q,t
of term t
in the query q, the weight w
d,t
of the term t in the document
d, and other factors. Fourth, after processing part [1,
6] or all of the lists, the accumulator scores are partially
sorted to identify the most similar documents. Last, for a
typical search engine, document summaries of the top ten
documents are generated or retrieved and shown to the user.
The offsets stored in each inverted list posting are not used
in ranked query processing.
Phrase queries require offsets and that a given sequence of
words be contiguous in a matching document. For example,
consider a combined ranked and phrase query:
"Matthew Richardson" Richmond
To evaluate such a query, the same first two steps as for
ranked querying are applied. Then, instead of accumulating
weights, it is necessary to construct a temporary inverted list
for the phrase, by fetching the inverted list of each of the
individual terms and combining them. If the inverted list for
"Matthew" is as above and the inverted list for "Richardson"
is
&lt; 1, 7, [52] &gt; &lt; 2, 12, [1, 4] &gt; &lt; 1, 44, [83] &gt;
then both words occur in document 7 and as an ordered
pair. Only the word "Richardson" is in document 12, both
words occur in document 44 but not as a pair, and only
"Matthew" occurs in document 117. The list for "Matthew
Richardson" is therefore
&lt; 1, 7, [51] &gt;
223
After this, the ranking process is continued from the third
step, where the list for the term "Richmond" and the newly
created list are used to adjust accumulator weights. Phrase
queries can involve more than two words.
COMPRESSING INVERTED INDEXES
Special-purpose integer compression schemes offer both
fast decoding and compact storage of inverted lists [13, 14].
In this section, we consider how inverted lists are compressed
and stored on disk. We limit our discussions here to the
special-purpose integer compression techniques that have
previously been shown to be suitable for index compression,
and focus on their use in increasing the speed of retrieval
systems.
Without compression, the time cost of retrieving inverted
lists is the sum of the time taken to seek for and then retrieve
the inverted lists from disk into memory, and the time taken
to transfer the lists from memory into the CPU cache before
they are processed. The speed of access to compressed
inverted lists is determined by two factors:first, the com-putational
requirements for decoding the compressed data
and, second, the time required to seek for and retrieve the
compressed data from disk and to transfer it to the CPU
cache before it is decoded. For a compression scheme to
allow faster access to inverted lists, the total retrieval time
and CPU processing costs should be less than the retrieval
time of the uncompressed representation. However, a third
factor makes compression attractive even if CPU processing
costs exceed the saving in disk transfer time:compressing
inverted lists increases the number of lists that can be
cached in memory between queries, so that in the context of
a stream of queries use of compression reduces the number
of disk accesses. It is therefore important that a compression
scheme be efficient in both decompression CPU costs
and space requirements.
There are two general classes of compression scheme that
are appropriate for storing inverted lists.
Variable-bit or
bitwise schemes store integers in an integral number of bits.
Well-known bitwise schemes include Elias gamma and delta
coding [3] and Golomb-Rice coding [4]. Bytewise schemes
store an integer in an integral number of blocks, where a
block is eight bits in size; we distinguish between blocks and
bytes here, since there is no implied restriction that a block
must align to a physical byte-boundary. A simple bytewise
scheme is variable-byte coding [2, 13]; uncompressed integers
are also stored in an integral number of blocks, but we
do not define them as bytewise schemes since, on most architectures
, an integer has a fixed-size representation of four
bytes. In detail, these schemes are as follows.
Elias coding [3] is a non-parameterised bitwise method of
coding integers. (Non-parameterised methods use static or
fixed codes to store integers.) The Elias gamma code represents
a positive integer k by 1 + log
2
k stored as a unary
code, followed by the binary representation of k without its
most significant bit. Using Elias gamma coding, small integers
are compactly represented; in particular, the integer 1
is represented as a single 1-bit. Gamma coding is relatively
inefficient for storing integers larger than 15 [13].
Elias delta codes are suited to coding larger integers, but
are inefficient for small values. For an integer k, a delta
code stores the gamma code representation of 1 + log
2
k ,
and then the binary representation of k without its most
significant bit.
Golomb-Rice bitwise coding [4] has been shown to offer
more compact storage of integers and faster retrieval than
the Elias codes [13]; indeed, it is bitwise optimal under the
assumption that the set of documents with a given term is
random. The codes are adapted to per-term likelihoods via
a parameter that is used to determine the code emitted for
an integer. In many cases, this parameter must be stored
separately using, for example, an Elias code. For coding of
inverted lists, a single parameter is used for all document
numbers in a postings list, but each posting requires a parameter
for its offsets. The parameters can be calculated as
the lists are decoded using statistics stored in memory and
in the lists, as we discuss later.
Coding of an integer k using Golomb codes with respect
to a parameter b is as follows. The code that is emitted is in
two parts:first, the unary code of a quotient q is emitted,
where q = (k - 1)/b + 1; second, a binary code is emitted
for the remainder r, where r = k - q × b - 1. The number
of bits required to store the remainder r is either log
2
b or
log
2
b . To retrieve the remainder, the value of the "toggle
point" t = 1 ((log
2
k)+1))-b is required, where
indicates
a left-shift operation. After retrieving
log
2
b bits of the
remainder r, the remainder is compared to t. If r &gt; t, then
one additional bit of the remainder must be retrieved. It
is generally thought that caching calculated values of log
2
b
is necessary for fast decoding, with a main-memory penalty
of having to store the values. However, as we show later,
when the standard log library function is replaced with a
fast bit-shifting version, caching is unnecessary.
Rice coding is a variant of Golomb coding where the value
of b is restricted to be a power of 2. The advantage of this
restriction is that there is no "toggle point" calculation required
, that is, the remainder is always stored in exactly
log
2
b bits. The disadvantage of this scheme is that the
choice of value for b is restricted and, therefore, the compression
is slightly less effective than that of Golomb coding.
For compression of inverted lists, a value of b is required.
Witten et al. [14] report that for cases where the probability
of any particular integer value occurring is small--which is
the usual case for document numbers d and offsets o--then
b can be calculated as:
b = 0.69 × mean(k)
For each inverted list, the mean value of document numbers
d can be approximated as k = N/f
t
where N is the number
of documents in the collection and f
t
is the number of postings
in the inverted list for term t [14]. This approach can
also be extended to offsets:the mean value of offsets o for
an inverted list posting can be approximated as k = l
d
/f
d,t
where l
d
is the length of document d and f
d,t
is the number
of offsets of term t within that document. As the statistics
N, f
t
, and l are often available in memory, or in a simple
auxiliary structure on disk, storage of b values is not required
for decoding; approximate values of l can be stored in memory
for compactness [7], but use of approximate values has
little effect on compression effectiveness as it leads to only
small relative errors in computation of b.
In bytewise coding an integer is stored in an integral number
of eight-bit blocks. For variable-byte codes, seven bits
in each block are used to store a binary representation of
the integer k. The remaining bit is used to indicate whether
the current block is the final block for k, or whether an additional
block follows. Consider an example of an integer k
224
in the range of 2
7
= 128 to 2
14
= 16, 384. Two blocks are
required to represent this integer:the first block contains
the seven least-significant bits of the integer and the eighth
bit is used to flag that another block follows; the second
block contains the remaining most-significant bits and the
eighth bit flags that no further blocks follow. We use the
convention that the flag bit is set to 1 in the final block and
0 otherwise.
Compressing an inverted index, then, involves choosing
compression schemes for the three kinds of data that are
stored in a posting:a document number d, an in-document
frequency f
d,t
, and a sequence of offsets o. A standard choice
is to use Golomb codes for document numbers, gamma codes
for frequencies, and delta codes for offsets [14]. (We explore
the properties of this choice later.) In this paper, we describe
such a choice as a GolD-GamF-DelO index.
3.1
Fast Decoding
We experiment with compression of inverted lists of postings
that contain frequencies f
d,t
, documents numbers d, and
offsets o. For fast decompression of these postings, there are
two important considerations:first, the choice of compression
scheme for each component of the posting; and, second,
modifications to each compression scheme so that it is both
fast and compatible with the schemes used for the other
components. In this section, we outline the optimisations
we use for fast decompression. Our code is publically available
and distributed under the GNU public licence.
2
Bitwise Compression
We have experimented with a range of variations of bitwise
decompression schemes. Williams and Zobel [13] reported
results for several efficient schemes, where vectors that contain
compressed integers are retrieved from disk and subse-quently
decoded.
3
In their approach, vector decoding uses
bitwise shift operations, bit masks, multiplication, subtraction
, and function calls to retrieve sequences of bits that
span byte boundaries. In our experiments on Intel Pentium-based
servers running the Linux operating system, we have
found that bitwise shift operations are usually faster than
bit masks, and that the function calls are slow. By opti-mising
our code to use bitwise shifts and to remove nested
function calls, we have found that the overall time to decode
vectors--regardless of the compression scheme used--is on
average around 60% of that using the code of Williams and
Zobel.
Other optimisations that are specific to Golomb-Rice coding
are also of value. Golomb-Rice decoding requires that
log
2
b is calculated to determine the number of remainder
bits to be retrieved.
It is practicable to explicitly cache
values of log
2
b in a hash table as they are calculated, or
to pre-calculate all likely-to-be-used values as the retrieval
query engine is initialised. This saves recalculation of logarithms
when a value of b is reused in later processing, with
the penalty of additional memory requirements for storing
the lookup table.
We measured the performance of Golomb coding with and
2
The
search
engine
used
in
these
experiments
and
our
integer
compression
code
is
available
from
http://www.seg.rmit.edu.au/
3
The code used by Williams and Zobel in their experiments
is available from http://www.cs.rmit.edu.au/
~hugh/software/
without caching. Timings are average elapsed query evaluation
cost to process index information for 25,000 queries on a
9.75 gigabyte (Gb) collection of Web data [5] using our prototype
retrieval engine on a GolD-GamF-GolO index (that
is, Golomb document numbers, gamma frequencies, Golomb
offsets); we discuss collection statistics and experimental design
further in Section 4. The cache lookup table size is
unrestricted.
We found that, without caching of log
2
b values, the average
query evaluation time is 0.961 seconds. Caching of
log
2
b values as they are calculated during query processing
roughly halves the average query evaluation time, to 0.494
seconds. Pre-calculating and storing the values offers almost
no benefit over caching during query processing, reducing
the time to 0.491 seconds; this reflects that only limited
b values are required during query evaluation. Caching of
toggle points yields 0.492 seconds. As toggle points are calculated
using bitwise shifts, addition, and subtraction, this
is further evidence that bitwise shifts are inexpensive on our
hardware.
An alternative approach to managing log computations
is to replace the standard library log function with a loop
that determines
log
2
b using bitwise shifts and equality
tests; the logarithm value can be determined by locating
the position of the most-significant 1-bit in b. We found
that this led to slight additional improvements in the speed
of decoding Golomb codes, outperforming explicit caching.
All Golomb-Rice coding results reported in this paper are
computed in this way.
Bytewise Compression
We have experimented with improvements to variable-byte
coding. Unlike in bitwise coding, we have found that masking
and shifting are equally as fast because of the large number
of shifts required. We use shifts in our experiments.
Perhaps the most obvious way to increase the speed of
variable-byte decoding is to align the eight-bit blocks to byte
boundaries. Alignment with byte boundaries limits the decoding
to only one option:the flag bit indicating if this is the
last byte in the integer is always the most significant bit, and
the remaining seven bits contain the value. Without byte
alignment, additional conditional tests and operations are
required to extract the flag bit, and the seven-bit value can
span byte boundaries. We would expect that byte alignment
would improve the speed of decoding variable-byte integers.
Figure 1 shows the effect of byte alignment of variable-byte
integers. In this experiment, variable-byte coding is
used to store the offsets o in each inverted list posting. The
optimised Golomb coding scheme described in the previous
section is used to code document numbers d and Elias
gamma coding is used to store the frequencies f
d,t
. We refer
to this as a GolD-GamF-VbyO index.
The graph at the left of Figure 1 shows total index size
as a percentage of the uncompressed collection being indexed
. The first bar shows that, without byte alignment,
the GolD-GamF-VbyO index requires almost 13% of the
space required by the collection. The second bar shows that
padding to byte alignment after storing the Gamma-coded
f
d,t
values increases the space requirement to just over 13.5%
of the collection size. We discuss the other schemes in this
figure later in this section.
The graph at the right of Figure 1 shows elapsed query
evaluation times using different index designs. Timings are
225
Original
Original with byte boundary
Signature block
Signature block with byte boundary
0
5
10
15
20
Size (% of Collection)
Original
Original with byte boundary
Signature block
Signature block with byte boundary
Scanning
Scanning with byte boundary
Scanning with signature block
Scanning with signature block and byte boundary
0.0
0.2
0.4
0.6
0.8
1.0
Average Query Time (Seconds)
Figure 1: Variable-byte schemes for compressing offsets
in inverted lists in a GolD-GamF-VbyOindex.
Four different compression schemes are shown and,
for each, both original and scanning decoding are
shown. Scanning decoding can be used when offsets
are not needed for query resolution.
the average elapsed query evaluation cost to process the
inverted lists for 25,000 queries on a 20 Gb collection of
Web [5] data using our prototype retrieval engine. Queries
are processed as conjunctive Boolean queries. The first bar
shows that the average time is around 0.7 seconds for the
GolD-GamF-VbyO index without byte alignment. The second
bar shows that the effect of byte alignment is a 25% reduction
in average query time. Therefore, despite the small
additional space requirement, byte-alignment is beneficial
when storing variable-byte integers.
A second optimisation to variable-byte coding is to consider
the query mode when processing the index. For querying
that does not use offsets--such as ranked and Boolean
querying--decoding of the offsets in each posting is unnecessary
. Rather, all that is required are the document numbers
d and document frequencies f
d,t
. An optimisation is therefore
to only examine the flag bit of each block and to ignore
the remaining seven bits that contain the value. The value
of f
d,t
indicates the number of offsets o stored in the posting
. By examining flag bits until f
d,t
1-bits are processed,
it is possible to bypass the offsets with minimal processing.
We call this approach scanning.
Scanning can also be used in query modes that do require
offset decoding. As we discussed earlier, phrase querying
requires that all terms are present in a matching document.
After processing the inverted list for the first term that is
evaluated in a phrase query, a temporary inverted list of
postings is created. This temporary list has a set D of documents
that contain the first term. When processing the
second term in the query, a second set of document numbers
D are processed. Offsets for the posting associated
with document d  D can be scanned, that is, passed over
without decoding, if d is not a member of D. (At the same
time, document numbers in D that are not in D are discarded
.)
We show the performance of scanning in Figure 1. The
fifth and sixth bars show how scanning affects query evaluation
time for variable-bytes that are either unaligned and
aligned to byte boundaries in the GolD-GamF-VbyO index.
Scanning removes the processing of seven-bit values. This
reduces the cost of retrieving unaligned variable-bytes to less
than that of the aligned variable-byte schemes; the small
speed advantage is due to the retrieval of smaller lists in the
unaligned version. Scanning has little effect on byte-aligned
variable bytes, reflecting that the processing of seven-bit values
using shift operations has a low cost. Overall, however,
byte-alignment is preferred since the decoding cost of offsets
is expensive in an unaligned scheme.
A third optimisation is an approach we call signature
blocks, which are a variant of skipping. Skipping is the approach
of storing additional integers in inverted lists that
indicate how much data can be skipped without any processing
[14]. Skipping has the disadvantage of an additional
storage space requirement, but has been shown to offer substantial
speed improvements [14]. A signature block is an
eight-bit block that stores the flag bits of up to eight blocks
that follow. For example, a signature block with the bit-string
11100101 represents that five integers are stored in
the eight following eight-bit blocks:the string 111 represents
that the first three blocks store one integer each; the
string 001 represents that the fourth integer is stored over
three blocks; and, the string 01 represents that the final integer
is stored over two blocks. As all flag bits are stored
in the signature block, the following blocks use all eight bits
to store values, rather the seven-bit scheme in the standard
variable-byte integer representation.
The primary use of signature blocks is skipping. To skip
offsets, f
d,t
offset values must be retrieved but not processed.
By counting the number of 1-bits in a signature block, the
number of integers stored in the next eight blocks can be
determined. If the value of f
d,t
exceeds this, then a second
or subsequent signature block is processed until f
d,t
offsets
have been skipped. The last signature block is, on average,
half full. We have found that bitwise shifts are faster than
a lookup table for processing of signature blocks.
The speed and space requirements are also shown in Figure
1. Not surprisingly, the signature block scheme requires
more space than the previous variable-byte schemes. This
space requirement is further increased if byte alignment of
blocks is enforced. In terms of speed, the third and fourth
bars in the right-hand histogram show that signature blocks
are slower than the original variable-byte schemes when offsets
are processed in the GolD-GamF-VbyO index. These
results are not surprising:signature blocks are slow to process
when they are unaligned, and the byte-aligned version
is slow because processing costs are no less than the original
variable-byte schemes and longer disk reads are required.
As shown by the seventh bar, when offsets are skipped the
unaligned signature block scheme is slower than the original
226
variable-byte scheme. The savings of skipping with signature
blocks are negated by more complex processing when
blocks are not byte-aligned. In contrast, the right-most bar
shows that the byte-aligned signature block scheme with
skipping is slightly faster on average than all other schemes.
However, we conclude--given the compactness of the index
and good overall performance--that the best all-round
scheme is the original variable-byte scheme with byte alignment
. Therefore, all variable-byte results reported in the
Section 4 use the original byte-aligned variable-byte scheme
with scanning.
Customised Compression
Combinations of bitwise and bytewise compression schemes
are also possible. The aim of such approaches is to combine
the fast decoding of bytewise schemes with the compact
storage of bitwise schemes. For example, a simple and
efficient custom scheme is to store a single bit that indicates
which of two compression schemes is used, and then to store
the integer using the designated compression scheme. We
have experimented with several approaches for storing offsets
. The simplest and most efficient approach we tested
is as follows:when f
d,t
= 1, we store a single bit indicating
whether the following offset is stored as a bitwise Elias
delta code or as a bytewise eight-bit binary representation.
When storing values, we use Elias delta coding if the value
is greater than 256 and the binary scheme otherwise. This
scheme has the potential to reduce space because in the median
posting f
d,t
is 1 and the average offset is around 200.
Selective use of a fixed-width representation can save storage
of the 6-bit prefix used to indicate magnitude in the
corresponding delta code.
We report the results with this scheme, which we call custom
, in the next section. This was the fastest custom scheme
we tested. Other approaches we tried included switching between
variable-byte and bitwise schemes, using the custom
scheme when f
d,t
is either 1 or 2, and other simple variations
. We omit results for these less successful approaches.
RESULTS
All experiments described in this paper are carried out on
an Intel Pentium III based machine with 512 Mb of main-memory
running the Linux operating system. Other processes
and disk activity was minimised during timing exp